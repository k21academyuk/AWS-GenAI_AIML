{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Train a Model\n",
    "\n",
    "The process of creating a machine learning (ML) model starts with data processing. After the data processing is complete, you choose an ML algorithm to train your model. The goal of model training is to create a model that you can use to make predictions with future data. Your processed data must contain a target, but your future data does not contain a target (it is unlabeled). The algorithm finds patterns in the training data that map the input data attributes to the target. The algorithm then outputs an ML model that captures these patterns. When you have a model, you can make predictions on new data that does not contain the target value.\n",
    "\n",
    "For example, if you want to train an ML model to predict if an email is spam or not spam, you would provide your model with training data that contains emails where you know the target (in this case, a label that tells whether an email is spam or not). Using this data, the algorithm creates a model that predicts if an email is spam or not spam. You can use this model to predict future email labels.\n",
    "\n",
    "In this task, you are predicting if someone has less than 50,000 USD or not. Your model is training to optimize itself so that it can predict if someone has less than 50,000 USD as accurately as possible. Model training requires some configuration, including which kind of algorithm you want to use to train. In this task, you use the XGBoost (eXtreme Gradient Boosting) algorithm. When you train a model, you also need to configure your hyperparameters. Hyperparameters are parameters that control the training job process. They can be adjusted to change various steps in the training job. Selecting the right set of hyperparameters is important in terms of model performance and accuracy. After you train the model, you evaluate the model and view the model artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Set up the environment\n",
    "\n",
    "Before you start training your model, install any necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:41:31.875643Z",
     "iopub.status.busy": "2025-07-17T10:41:31.874930Z",
     "iopub.status.idle": "2025-07-17T10:41:43.569701Z",
     "shell.execute_reply": "2025-07-17T10:41:43.568828Z",
     "shell.execute_reply.started": "2025-07-17T10:41:31.875617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: bokeh 2.4.2\n",
      "Uninstalling bokeh-2.4.2:\n",
      "  Successfully uninstalled bokeh-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting bokeh==2.4.2\n",
      "  Using cached bokeh-2.4.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (24.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (6.0.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (6.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from bokeh==2.4.2) (4.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from Jinja2>=2.9->bokeh==2.4.2) (3.0.2)\n",
      "Using cached bokeh-2.4.2-py3-none-any.whl (18.5 MB)\n",
      "Installing collected packages: bokeh\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "panel 1.7.2 requires bokeh<3.8.0,>=3.5.0, but you have bokeh 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bokeh-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.39.7)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.7 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.39.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.40.0,>=1.39.7->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.40.0,>=1.39.7->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.7->boto3) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.12/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install matplotlib\n",
    "%pip uninstall bokeh -y\n",
    "%pip install bokeh==2.4.2\n",
    "%pip install boto3\n",
    "%pip install seaborn\n",
    "\n",
    "# Install additional dependencies\n",
    "import boto3  # Ensure boto3 is imported\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from sagemaker import image_uris\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get execution role for SageMaker (IAM Role)\n",
    "role = sagemaker.get_execution_role()  # Automatically retrieves the role assigned to your SageMaker environment\n",
    "\n",
    "# Initialize boto3 session and get region information\n",
    "region = boto3.Session().region_name  # This retrieves the region name where the resources are located\n",
    "\n",
    "# Initialize the SageMaker client using boto3\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')  # SageMaker client to interact with SageMaker services\n",
    "\n",
    "# Now you can proceed with your training job or model deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the dataset. In the previous lab, you exported the data files from Amazon SageMaker Data Wrangler to an Amazon Simple Storage Service (Amazon S3) bucket. You split the dataset into training (70 percent), validation (20 percent), and test (10 percent) datasets. The training and validation datasets are used during training. The test dataset is used in model evaluation after deployment.\n",
    "\n",
    "The built-in Amazon SageMaker XGBoost algorithm supports several data formats like text/libsvm, text/csv, application/x-parquet and application/x-recordio-protobuf. This lab uses the CSV format for training. \n",
    "\n",
    "To view the dataset files that you created in the previous lab, follow these steps below:\n",
    "\n",
    "<!-- 1. Navigate to the AWS Management Console.\n",
    "\n",
    "1. At the top of the AWS Management Console, in the search bar, search for and choose `S3`.\n",
    "\n",
    "1. In the list of buckets, choose the Amazon S3 bucket that contains **labdatabucket** in its name.\n",
    "\n",
    "1. Choose the **scripts** folder, choose the **data** folder, choose the **train** folder\n",
    "\n",
    "1. Select the **adult_data_processed_train.csv** file and choose **Download** to view its contents.\n",
    "\n",
    "1. In the top of the page, choose **data** from the <i aria-hidden=\"true\" class=\"fas fa-folder\" style=\"color:white\"></i> **/ ... /data/train/** breadcrumbs link.\n",
    "\n",
    "1. Choose the **validation** folder.\n",
    "\n",
    "1. Select the **adult_data_processed_validation.csv** file and choose **Download** to view its contents.\n",
    "\n",
    "1. Return to the **lab_2.ipynb** notebook. -->\n",
    "\n",
    "1. Choose the bucket icon from the left menu bar.\n",
    "\n",
    "1. In the list of buckets, choose the Amazon S3 bucket that contains **labdatabucket** in its name.\n",
    "\n",
    "Opening the .csv files opens new tabs in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_2.ipynb** tab to the side or choose the **lab_2.ipynb** tab, and then from the toolbar, select **File** and **New View for Notebook**. You can now have the directions displayed as you explore the .csv files.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions. When you are finished exploring the .csv files, return to the notebook by choosing the **lab_2.ipynb** tab.\n",
    "\n",
    "1. Choose (double-click) the **scripts** folder, choose (double-click) the **data** folder, choose (double-click) the **train** folder, and then choose (double-click) the **adult_data_processed_train.csv** file to view its contents.\n",
    "\n",
    "1. In the left pane, choose **data** from the <i aria-hidden=\"true\" class=\"fas fa-folder\" style=\"color:white\"></i> **/ ... /data/train/** breadcrumbs link.\n",
    "\n",
    "1. Choose (double-click) the **validation** folder, and then choose (double-click) the **adult_data_processed_validation.csv** file to view its contents.\n",
    "\n",
    "You have viewed the dataset files. Now, configure the training and validation paths that your training job uses as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:41:43.571680Z",
     "iopub.status.busy": "2025-07-17T10:41:43.571367Z",
     "iopub.status.idle": "2025-07-17T10:41:43.795171Z",
     "shell.execute_reply": "2025-07-17T10:41:43.794407Z",
     "shell.execute_reply.started": "2025-07-17T10:41:43.571650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:  modeldevelopmentk21\n",
      "Training path: s3://modeldevelopmentk21/scripts/data/train/adult_data_processed_train.csv\n",
      "Validation path: s3://modeldevelopmentk21/scripts/data/validation/adult_data_processed_validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Import the datasets\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'modeldevelopmentk21' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(\"Bucket: \", bucket)\n",
    "prefix = 'scripts/data'\n",
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "# Configure the training paths\n",
    "train_path = f\"s3://{bucket}/{prefix}/train/adult_data_processed_train.csv\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation/adult_data_processed_validation.csv\"\n",
    "\n",
    "# Set up the TrainingInput objects\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "# Print the training and validation paths\n",
    "print(f'Training path: {train_path}')\n",
    "print(f'Validation path: {validation_path}')\n",
    "\n",
    "# Set the container, name, and tags\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "container = image_uris.retrieve(framework='xgboost',region=boto3.Session().region_name,version='1.5-1')\n",
    "run_name = 'lab-2-run-{}'.format(create_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Configure an estimator object\n",
    "\n",
    "An estimator is a high level interface for SageMaker training. You create an estimator object by supplying the required parameters, such as AWS Identity and Access Management (IAM) role, compute instance count and type, and the Amazon S3 output path. This lab uses the XGBoost built-in algorithm for the SageMaker generic estimator. XGBoost is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm that attempts to accurately predict a target variable by combining an ensemble of estimates from a set of simpler and weaker models. The XGBoost algorithm performs well in handling a variety of data types, relationships, distributions, and the variety of hyperparameters that you can fine-tune. You can use XGBoost for regression, classification (binary and multiclass), and ranking problems. In this case, you are using XGBoost to solve a classification problem (whether someone is making less than 50,000 USD or not).\n",
    "\n",
    "In this lab you create an XGBoost estimator by using the *sagemaker.estimator.Estimator* class. In the following example code, the XGBoost estimator is named *xgb_model*. To construct the SageMaker estimator, specify the following parameters:\n",
    "\n",
    "- **image_uri**: The training container image URI. In this example, the SageMaker XGBoost training container URI is specified using *image_uris.retrieve*.\n",
    "- **role**: The IAM role that SageMaker uses to perform tasks on your behalf (for example, reading training results, calling model artifacts from Amazon S3, and writing training results to Amazon S3). \n",
    "- **instance_count and instance_type**: The type and number of Amazon EC2 ML compute instances to use for model training. For this lab, you use a single ml.m5.xlarge instance, which has 4 CPUs, 16 GB of memory, an Amazon Elastic Block Store (Amazon EBS) storage, and a high network performance.\n",
    "- **output_path**: The path to the S3 bucket where SageMaker stores the model artifact and training results.\n",
    "- **sagemaker_session**: The session object that manages interactions with SageMaker API operations and other AWS service that the training job uses.\n",
    "- **rules**: A list of Amazon SageMaker Debugger built-in rules. In this example, the create_xgboost_report() rule creates an XGBoost report that provides insights into the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:41:43.799060Z",
     "iopub.status.busy": "2025-07-17T10:41:43.797562Z",
     "iopub.status.idle": "2025-07-17T10:41:43.843506Z",
     "shell.execute_reply": "2025-07-17T10:41:43.842806Z",
     "shell.execute_reply.started": "2025-07-17T10:41:43.799029Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = sagemaker.estimator.Estimator(\n",
    "    image_uri = container,\n",
    "    role = role, \n",
    "    instance_count = 1, \n",
    "    instance_type ='ml.m5.xlarge',\n",
    "    output_path = output_path,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    rules=[\n",
    "        Rule.sagemaker(rule_configs.create_xgboost_report())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Configure hyperparameters\n",
    "\n",
    "Hyperparameters directly control model structure, function, and performance. Hyperparameter tuning allows data scientists to tweak model performance for optimal results. This process is an essential part of machine learning, and choosing appropriate hyperparameter values is crucial for success.\n",
    "\n",
    "You can set hyperparameters for the XGBoost algorithm by calling the *set_hyperparameters* method of the estimator.\n",
    "\n",
    "Refer to [XGBoost Hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for more information about XGBoost hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:41:43.845294Z",
     "iopub.status.busy": "2025-07-17T10:41:43.844990Z",
     "iopub.status.idle": "2025-07-17T10:41:43.848605Z",
     "shell.execute_reply": "2025-07-17T10:41:43.847924Z",
     "shell.execute_reply.started": "2025-07-17T10:41:43.845265Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model.set_hyperparameters(\n",
    "    max_depth = 5,\n",
    "    eta = 0.2,\n",
    "    gamma = 4,\n",
    "    min_child_weight = 6,\n",
    "    subsample = 0.7,\n",
    "    verbosity = 0,\n",
    "    objective = 'binary:logistic',\n",
    "    num_round = 800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Run a SageMaker AI training job\n",
    "\n",
    "Now that you have configured your estimator object and hyperparameters, you are ready to start training the model. The fit() method starts the training script. To start model training, call the estimator's fit() method with the training and validation datasets. If you set `wait=True`, the fit() method displays progress logs and waits until training is complete.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** The training takes approximately 3â€“4 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:43:01.749653Z",
     "iopub.status.busy": "2025-07-17T10:43:01.748422Z",
     "iopub.status.idle": "2025-07-17T10:45:48.914307Z",
     "shell.execute_reply": "2025-07-17T10:45:48.913681Z",
     "shell.execute_reply.started": "2025-07-17T10:43:01.749613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-07-17-10-43-01-758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-17 10:43:02 Starting - Starting the training job...\n",
      "2025-07-17 10:43:28 Starting - Preparing the instances for trainingCreateXgboostReport: InProgress\n",
      "...\n",
      "2025-07-17 10:44:00 Downloading - Downloading input data...\n",
      "2025-07-17 10:44:20 Downloading - Downloading the training image...\n",
      "2025-07-17 10:45:00 Training - Training image download completed. Training in progress..\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.090 ip-10-0-99-218.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.112 ip-10-0-99-218.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Train matrix has 17343 rows and 13 columns\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Validation matrix has 2356 rows\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.525 ip-10-0-99-218.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.526 ip-10-0-99-218.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.526 ip-10-0-99-218.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.527 ip-10-0-99-218.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-07-17:10:45:05:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.566 ip-10-0-99-218.ec2.internal:7 INFO hook.py:427] Monitoring the collections: hyperparameters, feature_importance, labels, metrics, predictions\u001b[0m\n",
      "\u001b[34m[2025-07-17 10:45:05.568 ip-10-0-99-218.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.59441#011validation-logloss:0.59498\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.52963#011validation-logloss:0.53056\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.48197#011validation-logloss:0.48445\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.44733#011validation-logloss:0.45001\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.42042#011validation-logloss:0.42281\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.39984#011validation-logloss:0.40308\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.38367#011validation-logloss:0.38784\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.37111#011validation-logloss:0.37604\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.36077#011validation-logloss:0.36657\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.35288#011validation-logloss:0.35946\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.34650#011validation-logloss:0.35288\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.34104#011validation-logloss:0.34771\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.33551#011validation-logloss:0.34230\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.33164#011validation-logloss:0.33824\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.32818#011validation-logloss:0.33415\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.32544#011validation-logloss:0.33115\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.32283#011validation-logloss:0.32884\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.32046#011validation-logloss:0.32680\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.31833#011validation-logloss:0.32470\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.31677#011validation-logloss:0.32317\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.31532#011validation-logloss:0.32175\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.31391#011validation-logloss:0.32072\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.31244#011validation-logloss:0.31941\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.31073#011validation-logloss:0.31861\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.30963#011validation-logloss:0.31739\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.30870#011validation-logloss:0.31676\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.30757#011validation-logloss:0.31590\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.30592#011validation-logloss:0.31390\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.30545#011validation-logloss:0.31343\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.30410#011validation-logloss:0.31203\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.30358#011validation-logloss:0.31151\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.30324#011validation-logloss:0.31154\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.30237#011validation-logloss:0.31044\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.30188#011validation-logloss:0.30994\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.30147#011validation-logloss:0.30964\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.30091#011validation-logloss:0.30932\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.30018#011validation-logloss:0.30901\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.29963#011validation-logloss:0.30860\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.29926#011validation-logloss:0.30862\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.29892#011validation-logloss:0.30878\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.29802#011validation-logloss:0.30775\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.29751#011validation-logloss:0.30716\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.29700#011validation-logloss:0.30651\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.29662#011validation-logloss:0.30634\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.29625#011validation-logloss:0.30586\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.29549#011validation-logloss:0.30529\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.29533#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.29495#011validation-logloss:0.30529\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.29481#011validation-logloss:0.30510\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.29446#011validation-logloss:0.30521\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.29393#011validation-logloss:0.30454\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.29375#011validation-logloss:0.30436\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.29352#011validation-logloss:0.30421\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.29321#011validation-logloss:0.30400\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.29302#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.29281#011validation-logloss:0.30345\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.29248#011validation-logloss:0.30363\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.29218#011validation-logloss:0.30366\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.29176#011validation-logloss:0.30341\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.29166#011validation-logloss:0.30330\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.29135#011validation-logloss:0.30342\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.29125#011validation-logloss:0.30333\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.29110#011validation-logloss:0.30334\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.29087#011validation-logloss:0.30320\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.29058#011validation-logloss:0.30302\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.29021#011validation-logloss:0.30266\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.29013#011validation-logloss:0.30269\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.29003#011validation-logloss:0.30270\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.28989#011validation-logloss:0.30280\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.28978#011validation-logloss:0.30257\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.28937#011validation-logloss:0.30297\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.28922#011validation-logloss:0.30303\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.28894#011validation-logloss:0.30280\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.28883#011validation-logloss:0.30272\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.28852#011validation-logloss:0.30254\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.28841#011validation-logloss:0.30285\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.28831#011validation-logloss:0.30299\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.28810#011validation-logloss:0.30321\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.28802#011validation-logloss:0.30307\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.28791#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.28770#011validation-logloss:0.30299\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.28762#011validation-logloss:0.30312\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.28762#011validation-logloss:0.30311\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.28755#011validation-logloss:0.30316\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.28734#011validation-logloss:0.30268\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.28712#011validation-logloss:0.30305\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.28704#011validation-logloss:0.30297\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.28676#011validation-logloss:0.30298\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.28664#011validation-logloss:0.30299\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.28654#011validation-logloss:0.30291\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.28644#011validation-logloss:0.30279\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.28643#011validation-logloss:0.30281\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.28631#011validation-logloss:0.30263\u001b[0m\n",
      "\u001b[34m[93]#011train-logloss:0.28620#011validation-logloss:0.30248\u001b[0m\n",
      "\u001b[34m[94]#011train-logloss:0.28596#011validation-logloss:0.30228\u001b[0m\n",
      "\u001b[34m[95]#011train-logloss:0.28596#011validation-logloss:0.30229\u001b[0m\n",
      "\u001b[34m[96]#011train-logloss:0.28591#011validation-logloss:0.30223\u001b[0m\n",
      "\u001b[34m[97]#011train-logloss:0.28581#011validation-logloss:0.30218\u001b[0m\n",
      "\u001b[34m[98]#011train-logloss:0.28563#011validation-logloss:0.30220\u001b[0m\n",
      "\u001b[34m[99]#011train-logloss:0.28563#011validation-logloss:0.30223\u001b[0m\n",
      "\u001b[34m[100]#011train-logloss:0.28553#011validation-logloss:0.30218\u001b[0m\n",
      "\u001b[34m[101]#011train-logloss:0.28552#011validation-logloss:0.30217\u001b[0m\n",
      "\u001b[34m[102]#011train-logloss:0.28542#011validation-logloss:0.30195\u001b[0m\n",
      "\u001b[34m[103]#011train-logloss:0.28522#011validation-logloss:0.30179\u001b[0m\n",
      "\u001b[34m[104]#011train-logloss:0.28498#011validation-logloss:0.30190\u001b[0m\n",
      "\u001b[34m[105]#011train-logloss:0.28486#011validation-logloss:0.30179\u001b[0m\n",
      "\u001b[34m[106]#011train-logloss:0.28459#011validation-logloss:0.30177\u001b[0m\n",
      "\u001b[34m[107]#011train-logloss:0.28452#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[108]#011train-logloss:0.28452#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[109]#011train-logloss:0.28446#011validation-logloss:0.30146\u001b[0m\n",
      "\u001b[34m[110]#011train-logloss:0.28430#011validation-logloss:0.30129\u001b[0m\n",
      "\u001b[34m[111]#011train-logloss:0.28419#011validation-logloss:0.30144\u001b[0m\n",
      "\u001b[34m[112]#011train-logloss:0.28415#011validation-logloss:0.30142\u001b[0m\n",
      "\u001b[34m[113]#011train-logloss:0.28399#011validation-logloss:0.30161\u001b[0m\n",
      "\u001b[34m[114]#011train-logloss:0.28399#011validation-logloss:0.30162\u001b[0m\n",
      "\u001b[34m[115]#011train-logloss:0.28399#011validation-logloss:0.30162\u001b[0m\n",
      "\u001b[34m[116]#011train-logloss:0.28399#011validation-logloss:0.30156\u001b[0m\n",
      "\u001b[34m[117]#011train-logloss:0.28378#011validation-logloss:0.30158\u001b[0m\n",
      "\u001b[34m[118]#011train-logloss:0.28373#011validation-logloss:0.30165\u001b[0m\n",
      "\u001b[34m[119]#011train-logloss:0.28372#011validation-logloss:0.30152\u001b[0m\n",
      "\u001b[34m[120]#011train-logloss:0.28363#011validation-logloss:0.30164\u001b[0m\n",
      "\u001b[34m[121]#011train-logloss:0.28363#011validation-logloss:0.30162\u001b[0m\n",
      "\u001b[34m[122]#011train-logloss:0.28349#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[123]#011train-logloss:0.28349#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[124]#011train-logloss:0.28349#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[125]#011train-logloss:0.28349#011validation-logloss:0.30163\u001b[0m\n",
      "\u001b[34m[126]#011train-logloss:0.28349#011validation-logloss:0.30164\u001b[0m\n",
      "\u001b[34m[127]#011train-logloss:0.28328#011validation-logloss:0.30150\u001b[0m\n",
      "\u001b[34m[128]#011train-logloss:0.28317#011validation-logloss:0.30123\u001b[0m\n",
      "\u001b[34m[129]#011train-logloss:0.28304#011validation-logloss:0.30146\u001b[0m\n",
      "\u001b[34m[130]#011train-logloss:0.28296#011validation-logloss:0.30134\u001b[0m\n",
      "\u001b[34m[131]#011train-logloss:0.28296#011validation-logloss:0.30135\u001b[0m\n",
      "\u001b[34m[132]#011train-logloss:0.28296#011validation-logloss:0.30136\u001b[0m\n",
      "\u001b[34m[133]#011train-logloss:0.28283#011validation-logloss:0.30116\u001b[0m\n",
      "\u001b[34m[134]#011train-logloss:0.28275#011validation-logloss:0.30112\u001b[0m\n",
      "\u001b[34m[135]#011train-logloss:0.28263#011validation-logloss:0.30121\u001b[0m\n",
      "\u001b[34m[136]#011train-logloss:0.28252#011validation-logloss:0.30101\u001b[0m\n",
      "\u001b[34m[137]#011train-logloss:0.28231#011validation-logloss:0.30076\u001b[0m\n",
      "\u001b[34m[138]#011train-logloss:0.28231#011validation-logloss:0.30077\u001b[0m\n",
      "\u001b[34m[139]#011train-logloss:0.28231#011validation-logloss:0.30078\u001b[0m\n",
      "\u001b[34m[140]#011train-logloss:0.28208#011validation-logloss:0.30084\u001b[0m\n",
      "\u001b[34m[141]#011train-logloss:0.28188#011validation-logloss:0.30082\u001b[0m\n",
      "\u001b[34m[142]#011train-logloss:0.28179#011validation-logloss:0.30112\u001b[0m\n",
      "\u001b[34m[143]#011train-logloss:0.28179#011validation-logloss:0.30112\u001b[0m\n",
      "\u001b[34m[144]#011train-logloss:0.28173#011validation-logloss:0.30109\u001b[0m\n",
      "\u001b[34m[145]#011train-logloss:0.28168#011validation-logloss:0.30098\u001b[0m\n",
      "\u001b[34m[146]#011train-logloss:0.28162#011validation-logloss:0.30115\u001b[0m\n",
      "\u001b[34m[147]#011train-logloss:0.28160#011validation-logloss:0.30123\u001b[0m\n",
      "\u001b[34m[148]#011train-logloss:0.28153#011validation-logloss:0.30129\u001b[0m\n",
      "\u001b[34m[149]#011train-logloss:0.28123#011validation-logloss:0.30156\u001b[0m\n",
      "\u001b[34m[150]#011train-logloss:0.28119#011validation-logloss:0.30147\u001b[0m\n",
      "\u001b[34m[151]#011train-logloss:0.28119#011validation-logloss:0.30148\u001b[0m\n",
      "\u001b[34m[152]#011train-logloss:0.28119#011validation-logloss:0.30151\u001b[0m\n",
      "\u001b[34m[153]#011train-logloss:0.28119#011validation-logloss:0.30149\u001b[0m\n",
      "\u001b[34m[154]#011train-logloss:0.28119#011validation-logloss:0.30150\u001b[0m\n",
      "\u001b[34m[155]#011train-logloss:0.28094#011validation-logloss:0.30145\u001b[0m\n",
      "\u001b[34m[156]#011train-logloss:0.28094#011validation-logloss:0.30145\u001b[0m\n",
      "\u001b[34m[157]#011train-logloss:0.28085#011validation-logloss:0.30148\u001b[0m\n",
      "\u001b[34m[158]#011train-logloss:0.28078#011validation-logloss:0.30160\u001b[0m\n",
      "\u001b[34m[159]#011train-logloss:0.28067#011validation-logloss:0.30140\u001b[0m\n",
      "\u001b[34m[160]#011train-logloss:0.28067#011validation-logloss:0.30140\u001b[0m\n",
      "\u001b[34m[161]#011train-logloss:0.28067#011validation-logloss:0.30139\u001b[0m\n",
      "\u001b[34m[162]#011train-logloss:0.28059#011validation-logloss:0.30126\u001b[0m\n",
      "\u001b[34m[163]#011train-logloss:0.28059#011validation-logloss:0.30124\u001b[0m\n",
      "\u001b[34m[164]#011train-logloss:0.28059#011validation-logloss:0.30125\u001b[0m\n",
      "\u001b[34m[165]#011train-logloss:0.28059#011validation-logloss:0.30125\u001b[0m\n",
      "\u001b[34m[166]#011train-logloss:0.28059#011validation-logloss:0.30123\u001b[0m\n",
      "\u001b[34m[167]#011train-logloss:0.28047#011validation-logloss:0.30119\u001b[0m\n",
      "\u001b[34m[168]#011train-logloss:0.28027#011validation-logloss:0.30137\u001b[0m\n",
      "\u001b[34m[169]#011train-logloss:0.28020#011validation-logloss:0.30140\u001b[0m\n",
      "\u001b[34m[170]#011train-logloss:0.28015#011validation-logloss:0.30147\u001b[0m\n",
      "\u001b[34m[171]#011train-logloss:0.28015#011validation-logloss:0.30146\u001b[0m\n",
      "\u001b[34m[172]#011train-logloss:0.28003#011validation-logloss:0.30144\u001b[0m\n",
      "\u001b[34m[173]#011train-logloss:0.27990#011validation-logloss:0.30131\u001b[0m\n",
      "\u001b[34m[174]#011train-logloss:0.27980#011validation-logloss:0.30130\u001b[0m\n",
      "\u001b[34m[175]#011train-logloss:0.27969#011validation-logloss:0.30137\u001b[0m\n",
      "\u001b[34m[176]#011train-logloss:0.27953#011validation-logloss:0.30165\u001b[0m\n",
      "\u001b[34m[177]#011train-logloss:0.27947#011validation-logloss:0.30182\u001b[0m\n",
      "\u001b[34m[178]#011train-logloss:0.27931#011validation-logloss:0.30179\u001b[0m\n",
      "\u001b[34m[179]#011train-logloss:0.27922#011validation-logloss:0.30200\u001b[0m\n",
      "\u001b[34m[180]#011train-logloss:0.27914#011validation-logloss:0.30219\u001b[0m\n",
      "\u001b[34m[181]#011train-logloss:0.27907#011validation-logloss:0.30219\u001b[0m\n",
      "\u001b[34m[182]#011train-logloss:0.27903#011validation-logloss:0.30207\u001b[0m\n",
      "\u001b[34m[183]#011train-logloss:0.27903#011validation-logloss:0.30207\u001b[0m\n",
      "\u001b[34m[184]#011train-logloss:0.27903#011validation-logloss:0.30209\u001b[0m\n",
      "\u001b[34m[185]#011train-logloss:0.27891#011validation-logloss:0.30204\u001b[0m\n",
      "\u001b[34m[186]#011train-logloss:0.27886#011validation-logloss:0.30214\u001b[0m\n",
      "\u001b[34m[187]#011train-logloss:0.27886#011validation-logloss:0.30215\u001b[0m\n",
      "\u001b[34m[188]#011train-logloss:0.27886#011validation-logloss:0.30215\u001b[0m\n",
      "\u001b[34m[189]#011train-logloss:0.27886#011validation-logloss:0.30214\u001b[0m\n",
      "\u001b[34m[190]#011train-logloss:0.27882#011validation-logloss:0.30223\u001b[0m\n",
      "\u001b[34m[191]#011train-logloss:0.27882#011validation-logloss:0.30222\u001b[0m\n",
      "\u001b[34m[192]#011train-logloss:0.27877#011validation-logloss:0.30217\u001b[0m\n",
      "\u001b[34m[193]#011train-logloss:0.27875#011validation-logloss:0.30232\u001b[0m\n",
      "\u001b[34m[194]#011train-logloss:0.27874#011validation-logloss:0.30234\u001b[0m\n",
      "\u001b[34m[195]#011train-logloss:0.27875#011validation-logloss:0.30234\u001b[0m\n",
      "\u001b[34m[196]#011train-logloss:0.27875#011validation-logloss:0.30235\u001b[0m\n",
      "\u001b[34m[197]#011train-logloss:0.27875#011validation-logloss:0.30233\u001b[0m\n",
      "\u001b[34m[198]#011train-logloss:0.27870#011validation-logloss:0.30220\u001b[0m\n",
      "\u001b[34m[199]#011train-logloss:0.27870#011validation-logloss:0.30221\u001b[0m\n",
      "\u001b[34m[200]#011train-logloss:0.27859#011validation-logloss:0.30215\u001b[0m\n",
      "\u001b[34m[201]#011train-logloss:0.27859#011validation-logloss:0.30215\u001b[0m\n",
      "\u001b[34m[202]#011train-logloss:0.27853#011validation-logloss:0.30232\u001b[0m\n",
      "\u001b[34m[203]#011train-logloss:0.27849#011validation-logloss:0.30234\u001b[0m\n",
      "\u001b[34m[204]#011train-logloss:0.27849#011validation-logloss:0.30237\u001b[0m\n",
      "\u001b[34m[205]#011train-logloss:0.27849#011validation-logloss:0.30240\u001b[0m\n",
      "\u001b[34m[206]#011train-logloss:0.27849#011validation-logloss:0.30241\u001b[0m\n",
      "\u001b[34m[207]#011train-logloss:0.27849#011validation-logloss:0.30241\u001b[0m\n",
      "\u001b[34m[208]#011train-logloss:0.27849#011validation-logloss:0.30242\u001b[0m\n",
      "\u001b[34m[209]#011train-logloss:0.27846#011validation-logloss:0.30228\u001b[0m\n",
      "\u001b[34m[210]#011train-logloss:0.27838#011validation-logloss:0.30222\u001b[0m\n",
      "\u001b[34m[211]#011train-logloss:0.27833#011validation-logloss:0.30222\u001b[0m\n",
      "\u001b[34m[212]#011train-logloss:0.27831#011validation-logloss:0.30226\u001b[0m\n",
      "\u001b[34m[213]#011train-logloss:0.27832#011validation-logloss:0.30227\u001b[0m\n",
      "\u001b[34m[214]#011train-logloss:0.27831#011validation-logloss:0.30224\u001b[0m\n",
      "\u001b[34m[215]#011train-logloss:0.27824#011validation-logloss:0.30222\u001b[0m\n",
      "\u001b[34m[216]#011train-logloss:0.27824#011validation-logloss:0.30224\u001b[0m\n",
      "\u001b[34m[217]#011train-logloss:0.27822#011validation-logloss:0.30244\u001b[0m\n",
      "\u001b[34m[218]#011train-logloss:0.27813#011validation-logloss:0.30244\u001b[0m\n",
      "\u001b[34m[219]#011train-logloss:0.27813#011validation-logloss:0.30244\u001b[0m\n",
      "\u001b[34m[220]#011train-logloss:0.27813#011validation-logloss:0.30246\u001b[0m\n",
      "\u001b[34m[221]#011train-logloss:0.27810#011validation-logloss:0.30247\u001b[0m\n",
      "\u001b[34m[222]#011train-logloss:0.27810#011validation-logloss:0.30247\u001b[0m\n",
      "\u001b[34m[223]#011train-logloss:0.27810#011validation-logloss:0.30246\u001b[0m\n",
      "\u001b[34m[224]#011train-logloss:0.27800#011validation-logloss:0.30230\u001b[0m\n",
      "\u001b[34m[225]#011train-logloss:0.27800#011validation-logloss:0.30229\u001b[0m\n",
      "\u001b[34m[226]#011train-logloss:0.27800#011validation-logloss:0.30231\u001b[0m\n",
      "\u001b[34m[227]#011train-logloss:0.27800#011validation-logloss:0.30228\u001b[0m\n",
      "\u001b[34m[228]#011train-logloss:0.27800#011validation-logloss:0.30229\u001b[0m\n",
      "\u001b[34m[229]#011train-logloss:0.27782#011validation-logloss:0.30254\u001b[0m\n",
      "\u001b[34m[230]#011train-logloss:0.27776#011validation-logloss:0.30252\u001b[0m\n",
      "\u001b[34m[231]#011train-logloss:0.27771#011validation-logloss:0.30273\u001b[0m\n",
      "\u001b[34m[232]#011train-logloss:0.27771#011validation-logloss:0.30274\u001b[0m\n",
      "\u001b[34m[233]#011train-logloss:0.27767#011validation-logloss:0.30269\u001b[0m\n",
      "\u001b[34m[234]#011train-logloss:0.27767#011validation-logloss:0.30269\u001b[0m\n",
      "\u001b[34m[235]#011train-logloss:0.27756#011validation-logloss:0.30262\u001b[0m\n",
      "\u001b[34m[236]#011train-logloss:0.27756#011validation-logloss:0.30263\u001b[0m\n",
      "\u001b[34m[237]#011train-logloss:0.27756#011validation-logloss:0.30263\u001b[0m\n",
      "\u001b[34m[238]#011train-logloss:0.27749#011validation-logloss:0.30264\u001b[0m\n",
      "\u001b[34m[239]#011train-logloss:0.27749#011validation-logloss:0.30263\u001b[0m\n",
      "\u001b[34m[240]#011train-logloss:0.27749#011validation-logloss:0.30262\u001b[0m\n",
      "\u001b[34m[241]#011train-logloss:0.27749#011validation-logloss:0.30261\u001b[0m\n",
      "\u001b[34m[242]#011train-logloss:0.27749#011validation-logloss:0.30262\u001b[0m\n",
      "\u001b[34m[243]#011train-logloss:0.27749#011validation-logloss:0.30263\u001b[0m\n",
      "\u001b[34m[244]#011train-logloss:0.27749#011validation-logloss:0.30261\u001b[0m\n",
      "\u001b[34m[245]#011train-logloss:0.27738#011validation-logloss:0.30254\u001b[0m\n",
      "\u001b[34m[246]#011train-logloss:0.27738#011validation-logloss:0.30256\u001b[0m\n",
      "\u001b[34m[247]#011train-logloss:0.27738#011validation-logloss:0.30255\u001b[0m\n",
      "\u001b[34m[248]#011train-logloss:0.27738#011validation-logloss:0.30256\u001b[0m\n",
      "\u001b[34m[249]#011train-logloss:0.27738#011validation-logloss:0.30256\u001b[0m\n",
      "\u001b[34m[250]#011train-logloss:0.27730#011validation-logloss:0.30248\u001b[0m\n",
      "\u001b[34m[251]#011train-logloss:0.27730#011validation-logloss:0.30249\u001b[0m\n",
      "\u001b[34m[252]#011train-logloss:0.27730#011validation-logloss:0.30250\u001b[0m\n",
      "\u001b[34m[253]#011train-logloss:0.27726#011validation-logloss:0.30248\u001b[0m\n",
      "\u001b[34m[254]#011train-logloss:0.27726#011validation-logloss:0.30248\u001b[0m\n",
      "\u001b[34m[255]#011train-logloss:0.27724#011validation-logloss:0.30262\u001b[0m\n",
      "\u001b[34m[256]#011train-logloss:0.27723#011validation-logloss:0.30262\u001b[0m\n",
      "\u001b[34m[257]#011train-logloss:0.27706#011validation-logloss:0.30258\u001b[0m\n",
      "\u001b[34m[258]#011train-logloss:0.27707#011validation-logloss:0.30260\u001b[0m\n",
      "\u001b[34m[259]#011train-logloss:0.27689#011validation-logloss:0.30284\u001b[0m\n",
      "\u001b[34m[260]#011train-logloss:0.27689#011validation-logloss:0.30286\u001b[0m\n",
      "\u001b[34m[261]#011train-logloss:0.27689#011validation-logloss:0.30284\u001b[0m\n",
      "\u001b[34m[262]#011train-logloss:0.27689#011validation-logloss:0.30286\u001b[0m\n",
      "\u001b[34m[263]#011train-logloss:0.27681#011validation-logloss:0.30282\u001b[0m\n",
      "\u001b[34m[264]#011train-logloss:0.27671#011validation-logloss:0.30313\u001b[0m\n",
      "\u001b[34m[265]#011train-logloss:0.27671#011validation-logloss:0.30313\u001b[0m\n",
      "\u001b[34m[266]#011train-logloss:0.27663#011validation-logloss:0.30305\u001b[0m\n",
      "\u001b[34m[267]#011train-logloss:0.27661#011validation-logloss:0.30312\u001b[0m\n",
      "\u001b[34m[268]#011train-logloss:0.27661#011validation-logloss:0.30311\u001b[0m\n",
      "\u001b[34m[269]#011train-logloss:0.27661#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[270]#011train-logloss:0.27660#011validation-logloss:0.30308\u001b[0m\n",
      "\u001b[34m[271]#011train-logloss:0.27660#011validation-logloss:0.30307\u001b[0m\n",
      "\u001b[34m[272]#011train-logloss:0.27660#011validation-logloss:0.30307\u001b[0m\n",
      "\u001b[34m[273]#011train-logloss:0.27649#011validation-logloss:0.30294\u001b[0m\n",
      "\u001b[34m[274]#011train-logloss:0.27635#011validation-logloss:0.30285\u001b[0m\n",
      "\u001b[34m[275]#011train-logloss:0.27620#011validation-logloss:0.30266\u001b[0m\n",
      "\u001b[34m[276]#011train-logloss:0.27611#011validation-logloss:0.30282\u001b[0m\n",
      "\u001b[34m[277]#011train-logloss:0.27611#011validation-logloss:0.30283\u001b[0m\n",
      "\u001b[34m[278]#011train-logloss:0.27611#011validation-logloss:0.30281\u001b[0m\n",
      "\u001b[34m[279]#011train-logloss:0.27611#011validation-logloss:0.30280\u001b[0m\n",
      "\u001b[34m[280]#011train-logloss:0.27609#011validation-logloss:0.30297\u001b[0m\n",
      "\u001b[34m[281]#011train-logloss:0.27597#011validation-logloss:0.30291\u001b[0m\n",
      "\u001b[34m[282]#011train-logloss:0.27596#011validation-logloss:0.30289\u001b[0m\n",
      "\u001b[34m[283]#011train-logloss:0.27597#011validation-logloss:0.30293\u001b[0m\n",
      "\u001b[34m[284]#011train-logloss:0.27597#011validation-logloss:0.30292\u001b[0m\n",
      "\u001b[34m[285]#011train-logloss:0.27597#011validation-logloss:0.30293\u001b[0m\n",
      "\u001b[34m[286]#011train-logloss:0.27597#011validation-logloss:0.30293\u001b[0m\n",
      "\u001b[34m[287]#011train-logloss:0.27589#011validation-logloss:0.30273\u001b[0m\n",
      "\u001b[34m[288]#011train-logloss:0.27585#011validation-logloss:0.30309\u001b[0m\n",
      "\u001b[34m[289]#011train-logloss:0.27577#011validation-logloss:0.30304\u001b[0m\n",
      "\u001b[34m[290]#011train-logloss:0.27572#011validation-logloss:0.30307\u001b[0m\n",
      "\u001b[34m[291]#011train-logloss:0.27572#011validation-logloss:0.30307\u001b[0m\n",
      "\u001b[34m[292]#011train-logloss:0.27566#011validation-logloss:0.30303\u001b[0m\n",
      "\u001b[34m[293]#011train-logloss:0.27557#011validation-logloss:0.30297\u001b[0m\n",
      "\u001b[34m[294]#011train-logloss:0.27557#011validation-logloss:0.30299\u001b[0m\n",
      "\u001b[34m[295]#011train-logloss:0.27551#011validation-logloss:0.30312\u001b[0m\n",
      "\u001b[34m[296]#011train-logloss:0.27551#011validation-logloss:0.30312\u001b[0m\n",
      "\u001b[34m[297]#011train-logloss:0.27533#011validation-logloss:0.30315\u001b[0m\n",
      "\u001b[34m[298]#011train-logloss:0.27521#011validation-logloss:0.30296\u001b[0m\n",
      "\u001b[34m[299]#011train-logloss:0.27521#011validation-logloss:0.30298\u001b[0m\n",
      "\u001b[34m[300]#011train-logloss:0.27519#011validation-logloss:0.30304\u001b[0m\n",
      "\u001b[34m[301]#011train-logloss:0.27519#011validation-logloss:0.30303\u001b[0m\n",
      "\u001b[34m[302]#011train-logloss:0.27513#011validation-logloss:0.30302\u001b[0m\n",
      "\u001b[34m[303]#011train-logloss:0.27511#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[304]#011train-logloss:0.27511#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[305]#011train-logloss:0.27511#011validation-logloss:0.30308\u001b[0m\n",
      "\u001b[34m[306]#011train-logloss:0.27511#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[307]#011train-logloss:0.27511#011validation-logloss:0.30310\u001b[0m\n",
      "\u001b[34m[308]#011train-logloss:0.27500#011validation-logloss:0.30284\u001b[0m\n",
      "\u001b[34m[309]#011train-logloss:0.27489#011validation-logloss:0.30302\u001b[0m\n",
      "\u001b[34m[310]#011train-logloss:0.27480#011validation-logloss:0.30342\u001b[0m\n",
      "\u001b[34m[311]#011train-logloss:0.27480#011validation-logloss:0.30341\u001b[0m\n",
      "\u001b[34m[312]#011train-logloss:0.27479#011validation-logloss:0.30334\u001b[0m\n",
      "\u001b[34m[313]#011train-logloss:0.27475#011validation-logloss:0.30355\u001b[0m\n",
      "\u001b[34m[314]#011train-logloss:0.27476#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[315]#011train-logloss:0.27469#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[316]#011train-logloss:0.27469#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[317]#011train-logloss:0.27469#011validation-logloss:0.30355\u001b[0m\n",
      "\u001b[34m[318]#011train-logloss:0.27466#011validation-logloss:0.30340\u001b[0m\n",
      "\u001b[34m[319]#011train-logloss:0.27457#011validation-logloss:0.30340\u001b[0m\n",
      "\u001b[34m[320]#011train-logloss:0.27457#011validation-logloss:0.30339\u001b[0m\n",
      "\u001b[34m[321]#011train-logloss:0.27457#011validation-logloss:0.30338\u001b[0m\n",
      "\u001b[34m[322]#011train-logloss:0.27446#011validation-logloss:0.30344\u001b[0m\n",
      "\u001b[34m[323]#011train-logloss:0.27446#011validation-logloss:0.30345\u001b[0m\n",
      "\u001b[34m[324]#011train-logloss:0.27446#011validation-logloss:0.30345\u001b[0m\n",
      "\u001b[34m[325]#011train-logloss:0.27446#011validation-logloss:0.30346\u001b[0m\n",
      "\u001b[34m[326]#011train-logloss:0.27435#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[327]#011train-logloss:0.27435#011validation-logloss:0.30370\u001b[0m\n",
      "\u001b[34m[328]#011train-logloss:0.27435#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[329]#011train-logloss:0.27435#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[330]#011train-logloss:0.27435#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[331]#011train-logloss:0.27432#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[332]#011train-logloss:0.27432#011validation-logloss:0.30370\u001b[0m\n",
      "\u001b[34m[333]#011train-logloss:0.27432#011validation-logloss:0.30368\u001b[0m\n",
      "\u001b[34m[334]#011train-logloss:0.27432#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[335]#011train-logloss:0.27432#011validation-logloss:0.30367\u001b[0m\n",
      "\u001b[34m[336]#011train-logloss:0.27426#011validation-logloss:0.30385\u001b[0m\n",
      "\u001b[34m[337]#011train-logloss:0.27417#011validation-logloss:0.30358\u001b[0m\n",
      "\u001b[34m[338]#011train-logloss:0.27407#011validation-logloss:0.30358\u001b[0m\n",
      "\u001b[34m[339]#011train-logloss:0.27407#011validation-logloss:0.30358\u001b[0m\n",
      "\u001b[34m[340]#011train-logloss:0.27407#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[341]#011train-logloss:0.27400#011validation-logloss:0.30352\u001b[0m\n",
      "\u001b[34m[342]#011train-logloss:0.27395#011validation-logloss:0.30352\u001b[0m\n",
      "\u001b[34m[343]#011train-logloss:0.27379#011validation-logloss:0.30369\u001b[0m\n",
      "\u001b[34m[344]#011train-logloss:0.27379#011validation-logloss:0.30371\u001b[0m\n",
      "\u001b[34m[345]#011train-logloss:0.27379#011validation-logloss:0.30373\u001b[0m\n",
      "\u001b[34m[346]#011train-logloss:0.27370#011validation-logloss:0.30408\u001b[0m\n",
      "\u001b[34m[347]#011train-logloss:0.27367#011validation-logloss:0.30405\u001b[0m\n",
      "\u001b[34m[348]#011train-logloss:0.27360#011validation-logloss:0.30431\u001b[0m\n",
      "\u001b[34m[349]#011train-logloss:0.27350#011validation-logloss:0.30437\u001b[0m\n",
      "\u001b[34m[350]#011train-logloss:0.27350#011validation-logloss:0.30440\u001b[0m\n",
      "\u001b[34m[351]#011train-logloss:0.27349#011validation-logloss:0.30437\u001b[0m\n",
      "\u001b[34m[352]#011train-logloss:0.27345#011validation-logloss:0.30423\u001b[0m\n",
      "\u001b[34m[353]#011train-logloss:0.27345#011validation-logloss:0.30421\u001b[0m\n",
      "\u001b[34m[354]#011train-logloss:0.27345#011validation-logloss:0.30421\u001b[0m\n",
      "\u001b[34m[355]#011train-logloss:0.27345#011validation-logloss:0.30422\u001b[0m\n",
      "\u001b[34m[356]#011train-logloss:0.27345#011validation-logloss:0.30420\u001b[0m\n",
      "\u001b[34m[357]#011train-logloss:0.27337#011validation-logloss:0.30402\u001b[0m\n",
      "\u001b[34m[358]#011train-logloss:0.27331#011validation-logloss:0.30405\u001b[0m\n",
      "\u001b[34m[359]#011train-logloss:0.27331#011validation-logloss:0.30405\u001b[0m\n",
      "\u001b[34m[360]#011train-logloss:0.27331#011validation-logloss:0.30407\u001b[0m\n",
      "\u001b[34m[361]#011train-logloss:0.27331#011validation-logloss:0.30405\u001b[0m\n",
      "\u001b[34m[362]#011train-logloss:0.27331#011validation-logloss:0.30406\u001b[0m\n",
      "\u001b[34m[363]#011train-logloss:0.27321#011validation-logloss:0.30391\u001b[0m\n",
      "\u001b[34m[364]#011train-logloss:0.27321#011validation-logloss:0.30390\u001b[0m\n",
      "\u001b[34m[365]#011train-logloss:0.27321#011validation-logloss:0.30390\u001b[0m\n",
      "\u001b[34m[366]#011train-logloss:0.27321#011validation-logloss:0.30389\u001b[0m\n",
      "\u001b[34m[367]#011train-logloss:0.27312#011validation-logloss:0.30381\u001b[0m\n",
      "\u001b[34m[368]#011train-logloss:0.27306#011validation-logloss:0.30364\u001b[0m\n",
      "\u001b[34m[369]#011train-logloss:0.27306#011validation-logloss:0.30364\u001b[0m\n",
      "\u001b[34m[370]#011train-logloss:0.27299#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[371]#011train-logloss:0.27299#011validation-logloss:0.30356\u001b[0m\n",
      "\u001b[34m[372]#011train-logloss:0.27299#011validation-logloss:0.30358\u001b[0m\n",
      "\u001b[34m[373]#011train-logloss:0.27294#011validation-logloss:0.30357\u001b[0m\n",
      "\u001b[34m[374]#011train-logloss:0.27292#011validation-logloss:0.30333\u001b[0m\n",
      "\u001b[34m[375]#011train-logloss:0.27292#011validation-logloss:0.30335\u001b[0m\n",
      "\u001b[34m[376]#011train-logloss:0.27292#011validation-logloss:0.30334\u001b[0m\n",
      "\u001b[34m[377]#011train-logloss:0.27292#011validation-logloss:0.30335\u001b[0m\n",
      "\u001b[34m[378]#011train-logloss:0.27292#011validation-logloss:0.30336\u001b[0m\n",
      "\u001b[34m[379]#011train-logloss:0.27284#011validation-logloss:0.30353\u001b[0m\n",
      "\u001b[34m[380]#011train-logloss:0.27284#011validation-logloss:0.30353\u001b[0m\n",
      "\u001b[34m[381]#011train-logloss:0.27280#011validation-logloss:0.30339\u001b[0m\n",
      "\u001b[34m[382]#011train-logloss:0.27280#011validation-logloss:0.30337\u001b[0m\n",
      "\u001b[34m[383]#011train-logloss:0.27275#011validation-logloss:0.30351\u001b[0m\n",
      "\u001b[34m[384]#011train-logloss:0.27263#011validation-logloss:0.30375\u001b[0m\n",
      "\u001b[34m[385]#011train-logloss:0.27247#011validation-logloss:0.30378\u001b[0m\n",
      "\u001b[34m[386]#011train-logloss:0.27247#011validation-logloss:0.30379\u001b[0m\n",
      "\u001b[34m[387]#011train-logloss:0.27242#011validation-logloss:0.30397\u001b[0m\n",
      "\u001b[34m[388]#011train-logloss:0.27238#011validation-logloss:0.30419\u001b[0m\n",
      "\u001b[34m[389]#011train-logloss:0.27236#011validation-logloss:0.30437\u001b[0m\n",
      "\u001b[34m[390]#011train-logloss:0.27235#011validation-logloss:0.30457\u001b[0m\n",
      "\u001b[34m[391]#011train-logloss:0.27235#011validation-logloss:0.30459\u001b[0m\n",
      "\u001b[34m[392]#011train-logloss:0.27235#011validation-logloss:0.30460\u001b[0m\n",
      "\u001b[34m[393]#011train-logloss:0.27235#011validation-logloss:0.30459\u001b[0m\n",
      "\u001b[34m[394]#011train-logloss:0.27235#011validation-logloss:0.30461\u001b[0m\n",
      "\u001b[34m[395]#011train-logloss:0.27230#011validation-logloss:0.30475\u001b[0m\n",
      "\u001b[34m[396]#011train-logloss:0.27231#011validation-logloss:0.30476\u001b[0m\n",
      "\u001b[34m[397]#011train-logloss:0.27226#011validation-logloss:0.30463\u001b[0m\n",
      "\u001b[34m[398]#011train-logloss:0.27226#011validation-logloss:0.30463\u001b[0m\n",
      "\u001b[34m[399]#011train-logloss:0.27226#011validation-logloss:0.30462\u001b[0m\n",
      "\u001b[34m[400]#011train-logloss:0.27222#011validation-logloss:0.30463\u001b[0m\n",
      "\u001b[34m[401]#011train-logloss:0.27221#011validation-logloss:0.30471\u001b[0m\n",
      "\u001b[34m[402]#011train-logloss:0.27218#011validation-logloss:0.30461\u001b[0m\n",
      "\u001b[34m[403]#011train-logloss:0.27218#011validation-logloss:0.30463\u001b[0m\n",
      "\u001b[34m[404]#011train-logloss:0.27217#011validation-logloss:0.30458\u001b[0m\n",
      "\u001b[34m[405]#011train-logloss:0.27205#011validation-logloss:0.30495\u001b[0m\n",
      "\u001b[34m[406]#011train-logloss:0.27200#011validation-logloss:0.30486\u001b[0m\n",
      "\u001b[34m[407]#011train-logloss:0.27200#011validation-logloss:0.30487\u001b[0m\n",
      "\u001b[34m[408]#011train-logloss:0.27200#011validation-logloss:0.30487\u001b[0m\n",
      "\u001b[34m[409]#011train-logloss:0.27198#011validation-logloss:0.30452\u001b[0m\n",
      "\u001b[34m[410]#011train-logloss:0.27198#011validation-logloss:0.30452\u001b[0m\n",
      "\u001b[34m[411]#011train-logloss:0.27198#011validation-logloss:0.30450\u001b[0m\n",
      "\u001b[34m[412]#011train-logloss:0.27198#011validation-logloss:0.30451\u001b[0m\n",
      "\u001b[34m[413]#011train-logloss:0.27198#011validation-logloss:0.30450\u001b[0m\n",
      "\u001b[34m[414]#011train-logloss:0.27198#011validation-logloss:0.30452\u001b[0m\n",
      "\u001b[34m[415]#011train-logloss:0.27198#011validation-logloss:0.30451\u001b[0m\n",
      "\u001b[34m[416]#011train-logloss:0.27198#011validation-logloss:0.30451\u001b[0m\n",
      "\u001b[34m[417]#011train-logloss:0.27198#011validation-logloss:0.30450\u001b[0m\n",
      "\u001b[34m[418]#011train-logloss:0.27198#011validation-logloss:0.30449\u001b[0m\n",
      "\u001b[34m[419]#011train-logloss:0.27198#011validation-logloss:0.30448\u001b[0m\n",
      "\u001b[34m[420]#011train-logloss:0.27193#011validation-logloss:0.30448\u001b[0m\n",
      "\u001b[34m[421]#011train-logloss:0.27194#011validation-logloss:0.30449\u001b[0m\n",
      "\u001b[34m[422]#011train-logloss:0.27193#011validation-logloss:0.30447\u001b[0m\n",
      "\u001b[34m[423]#011train-logloss:0.27184#011validation-logloss:0.30432\u001b[0m\n",
      "\u001b[34m[424]#011train-logloss:0.27184#011validation-logloss:0.30433\u001b[0m\n",
      "\u001b[34m[425]#011train-logloss:0.27178#011validation-logloss:0.30442\u001b[0m\n",
      "\u001b[34m[426]#011train-logloss:0.27178#011validation-logloss:0.30443\u001b[0m\n",
      "\u001b[34m[427]#011train-logloss:0.27170#011validation-logloss:0.30434\u001b[0m\n",
      "\u001b[34m[428]#011train-logloss:0.27166#011validation-logloss:0.30417\u001b[0m\n",
      "\u001b[34m[429]#011train-logloss:0.27158#011validation-logloss:0.30440\u001b[0m\n",
      "\u001b[34m[430]#011train-logloss:0.27146#011validation-logloss:0.30467\u001b[0m\n",
      "\u001b[34m[431]#011train-logloss:0.27146#011validation-logloss:0.30470\u001b[0m\n",
      "\u001b[34m[432]#011train-logloss:0.27138#011validation-logloss:0.30484\u001b[0m\n",
      "\u001b[34m[433]#011train-logloss:0.27138#011validation-logloss:0.30484\u001b[0m\n",
      "\u001b[34m[434]#011train-logloss:0.27138#011validation-logloss:0.30485\u001b[0m\n",
      "\u001b[34m[435]#011train-logloss:0.27138#011validation-logloss:0.30485\u001b[0m\n",
      "\u001b[34m[436]#011train-logloss:0.27133#011validation-logloss:0.30493\u001b[0m\n",
      "\u001b[34m[437]#011train-logloss:0.27126#011validation-logloss:0.30496\u001b[0m\n",
      "\u001b[34m[438]#011train-logloss:0.27120#011validation-logloss:0.30513\u001b[0m\n",
      "\u001b[34m[439]#011train-logloss:0.27111#011validation-logloss:0.30514\u001b[0m\n",
      "\u001b[34m[440]#011train-logloss:0.27111#011validation-logloss:0.30514\u001b[0m\n",
      "\u001b[34m[441]#011train-logloss:0.27111#011validation-logloss:0.30516\u001b[0m\n",
      "\u001b[34m[442]#011train-logloss:0.27108#011validation-logloss:0.30513\u001b[0m\n",
      "\u001b[34m[443]#011train-logloss:0.27109#011validation-logloss:0.30515\u001b[0m\n",
      "\u001b[34m[444]#011train-logloss:0.27106#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[445]#011train-logloss:0.27106#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[446]#011train-logloss:0.27106#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[447]#011train-logloss:0.27106#011validation-logloss:0.30530\u001b[0m\n",
      "\u001b[34m[448]#011train-logloss:0.27105#011validation-logloss:0.30529\u001b[0m\n",
      "\u001b[34m[449]#011train-logloss:0.27106#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[450]#011train-logloss:0.27102#011validation-logloss:0.30523\u001b[0m\n",
      "\u001b[34m[451]#011train-logloss:0.27098#011validation-logloss:0.30509\u001b[0m\n",
      "\u001b[34m[452]#011train-logloss:0.27098#011validation-logloss:0.30508\u001b[0m\n",
      "\u001b[34m[453]#011train-logloss:0.27098#011validation-logloss:0.30509\u001b[0m\n",
      "\u001b[34m[454]#011train-logloss:0.27098#011validation-logloss:0.30510\u001b[0m\n",
      "\u001b[34m[455]#011train-logloss:0.27093#011validation-logloss:0.30534\u001b[0m\n",
      "\u001b[34m[456]#011train-logloss:0.27093#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[457]#011train-logloss:0.27093#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[458]#011train-logloss:0.27093#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[459]#011train-logloss:0.27093#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[460]#011train-logloss:0.27090#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[461]#011train-logloss:0.27090#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[462]#011train-logloss:0.27080#011validation-logloss:0.30542\u001b[0m\n",
      "\u001b[34m[463]#011train-logloss:0.27080#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[464]#011train-logloss:0.27080#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[465]#011train-logloss:0.27080#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[466]#011train-logloss:0.27080#011validation-logloss:0.30541\u001b[0m\n",
      "\u001b[34m[467]#011train-logloss:0.27080#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[468]#011train-logloss:0.27080#011validation-logloss:0.30539\u001b[0m\n",
      "\u001b[34m[469]#011train-logloss:0.27080#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[470]#011train-logloss:0.27080#011validation-logloss:0.30539\u001b[0m\n",
      "\u001b[34m[471]#011train-logloss:0.27076#011validation-logloss:0.30527\u001b[0m\n",
      "\u001b[34m[472]#011train-logloss:0.27073#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[473]#011train-logloss:0.27073#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[474]#011train-logloss:0.27074#011validation-logloss:0.30538\u001b[0m\n",
      "\u001b[34m[475]#011train-logloss:0.27073#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[476]#011train-logloss:0.27073#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[477]#011train-logloss:0.27074#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[478]#011train-logloss:0.27066#011validation-logloss:0.30552\u001b[0m\n",
      "\u001b[34m[479]#011train-logloss:0.27066#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[480]#011train-logloss:0.27066#011validation-logloss:0.30550\u001b[0m\n",
      "\u001b[34m[481]#011train-logloss:0.27066#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[482]#011train-logloss:0.27066#011validation-logloss:0.30553\u001b[0m\n",
      "\u001b[34m[483]#011train-logloss:0.27066#011validation-logloss:0.30554\u001b[0m\n",
      "\u001b[34m[484]#011train-logloss:0.27066#011validation-logloss:0.30554\u001b[0m\n",
      "\u001b[34m[485]#011train-logloss:0.27066#011validation-logloss:0.30554\u001b[0m\n",
      "\u001b[34m[486]#011train-logloss:0.27057#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[487]#011train-logloss:0.27053#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[488]#011train-logloss:0.27053#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[489]#011train-logloss:0.27053#011validation-logloss:0.30535\u001b[0m\n",
      "\u001b[34m[490]#011train-logloss:0.27053#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[491]#011train-logloss:0.27053#011validation-logloss:0.30534\u001b[0m\n",
      "\u001b[34m[492]#011train-logloss:0.27053#011validation-logloss:0.30534\u001b[0m\n",
      "\u001b[34m[493]#011train-logloss:0.27053#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[494]#011train-logloss:0.27053#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[495]#011train-logloss:0.27045#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[496]#011train-logloss:0.27045#011validation-logloss:0.30530\u001b[0m\n",
      "\u001b[34m[497]#011train-logloss:0.27045#011validation-logloss:0.30527\u001b[0m\n",
      "\u001b[34m[498]#011train-logloss:0.27045#011validation-logloss:0.30527\u001b[0m\n",
      "\u001b[34m[499]#011train-logloss:0.27040#011validation-logloss:0.30512\u001b[0m\n",
      "\u001b[34m[500]#011train-logloss:0.27040#011validation-logloss:0.30513\u001b[0m\n",
      "\u001b[34m[501]#011train-logloss:0.27040#011validation-logloss:0.30513\u001b[0m\n",
      "\u001b[34m[502]#011train-logloss:0.27040#011validation-logloss:0.30514\u001b[0m\n",
      "\u001b[34m[503]#011train-logloss:0.27040#011validation-logloss:0.30516\u001b[0m\n",
      "\u001b[34m[504]#011train-logloss:0.27040#011validation-logloss:0.30515\u001b[0m\n",
      "\u001b[34m[505]#011train-logloss:0.27040#011validation-logloss:0.30515\u001b[0m\n",
      "\u001b[34m[506]#011train-logloss:0.27035#011validation-logloss:0.30516\u001b[0m\n",
      "\u001b[34m[507]#011train-logloss:0.27035#011validation-logloss:0.30515\u001b[0m\n",
      "\u001b[34m[508]#011train-logloss:0.27027#011validation-logloss:0.30529\u001b[0m\n",
      "\u001b[34m[509]#011train-logloss:0.27027#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[510]#011train-logloss:0.27027#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[511]#011train-logloss:0.27027#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[512]#011train-logloss:0.27016#011validation-logloss:0.30517\u001b[0m\n",
      "\u001b[34m[513]#011train-logloss:0.27015#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[514]#011train-logloss:0.27015#011validation-logloss:0.30518\u001b[0m\n",
      "\u001b[34m[515]#011train-logloss:0.27015#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[516]#011train-logloss:0.27015#011validation-logloss:0.30520\u001b[0m\n",
      "\u001b[34m[517]#011train-logloss:0.27015#011validation-logloss:0.30520\u001b[0m\n",
      "\u001b[34m[518]#011train-logloss:0.27015#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[519]#011train-logloss:0.27015#011validation-logloss:0.30520\u001b[0m\n",
      "\u001b[34m[520]#011train-logloss:0.27015#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[521]#011train-logloss:0.27015#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[522]#011train-logloss:0.27015#011validation-logloss:0.30522\u001b[0m\n",
      "\u001b[34m[523]#011train-logloss:0.27016#011validation-logloss:0.30520\u001b[0m\n",
      "\u001b[34m[524]#011train-logloss:0.27016#011validation-logloss:0.30521\u001b[0m\n",
      "\u001b[34m[525]#011train-logloss:0.27014#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[526]#011train-logloss:0.27014#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[527]#011train-logloss:0.27012#011validation-logloss:0.30518\u001b[0m\n",
      "\u001b[34m[528]#011train-logloss:0.27012#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[529]#011train-logloss:0.27012#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[530]#011train-logloss:0.27012#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[531]#011train-logloss:0.27012#011validation-logloss:0.30520\u001b[0m\n",
      "\u001b[34m[532]#011train-logloss:0.27012#011validation-logloss:0.30519\u001b[0m\n",
      "\u001b[34m[533]#011train-logloss:0.27004#011validation-logloss:0.30550\u001b[0m\n",
      "\u001b[34m[534]#011train-logloss:0.27004#011validation-logloss:0.30549\u001b[0m\n",
      "\u001b[34m[535]#011train-logloss:0.27000#011validation-logloss:0.30577\u001b[0m\n",
      "\u001b[34m[536]#011train-logloss:0.27000#011validation-logloss:0.30577\u001b[0m\n",
      "\u001b[34m[537]#011train-logloss:0.26999#011validation-logloss:0.30552\u001b[0m\n",
      "\u001b[34m[538]#011train-logloss:0.26999#011validation-logloss:0.30553\u001b[0m\n",
      "\u001b[34m[539]#011train-logloss:0.26992#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[540]#011train-logloss:0.26992#011validation-logloss:0.30538\u001b[0m\n",
      "\u001b[34m[541]#011train-logloss:0.26992#011validation-logloss:0.30538\u001b[0m\n",
      "\u001b[34m[542]#011train-logloss:0.26992#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[543]#011train-logloss:0.26992#011validation-logloss:0.30538\u001b[0m\n",
      "\u001b[34m[544]#011train-logloss:0.26992#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[545]#011train-logloss:0.26992#011validation-logloss:0.30539\u001b[0m\n",
      "\u001b[34m[546]#011train-logloss:0.26992#011validation-logloss:0.30537\u001b[0m\n",
      "\u001b[34m[547]#011train-logloss:0.26992#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[548]#011train-logloss:0.26992#011validation-logloss:0.30537\u001b[0m\n",
      "\u001b[34m[549]#011train-logloss:0.26978#011validation-logloss:0.30543\u001b[0m\n",
      "\u001b[34m[550]#011train-logloss:0.26978#011validation-logloss:0.30541\u001b[0m\n",
      "\u001b[34m[551]#011train-logloss:0.26973#011validation-logloss:0.30544\u001b[0m\n",
      "\u001b[34m[552]#011train-logloss:0.26967#011validation-logloss:0.30527\u001b[0m\n",
      "\u001b[34m[553]#011train-logloss:0.26951#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[554]#011train-logloss:0.26951#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[555]#011train-logloss:0.26951#011validation-logloss:0.30548\u001b[0m\n",
      "\u001b[34m[556]#011train-logloss:0.26939#011validation-logloss:0.30538\u001b[0m\n",
      "\u001b[34m[557]#011train-logloss:0.26933#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[558]#011train-logloss:0.26933#011validation-logloss:0.30553\u001b[0m\n",
      "\u001b[34m[559]#011train-logloss:0.26933#011validation-logloss:0.30553\u001b[0m\n",
      "\u001b[34m[560]#011train-logloss:0.26933#011validation-logloss:0.30554\u001b[0m\n",
      "\u001b[34m[561]#011train-logloss:0.26934#011validation-logloss:0.30554\u001b[0m\n",
      "\u001b[34m[562]#011train-logloss:0.26931#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[563]#011train-logloss:0.26931#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[564]#011train-logloss:0.26931#011validation-logloss:0.30540\u001b[0m\n",
      "\u001b[34m[565]#011train-logloss:0.26931#011validation-logloss:0.30537\u001b[0m\n",
      "\u001b[34m[566]#011train-logloss:0.26931#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[567]#011train-logloss:0.26931#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[568]#011train-logloss:0.26926#011validation-logloss:0.30534\u001b[0m\n",
      "\u001b[34m[569]#011train-logloss:0.26920#011validation-logloss:0.30539\u001b[0m\n",
      "\u001b[34m[570]#011train-logloss:0.26920#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[571]#011train-logloss:0.26920#011validation-logloss:0.30536\u001b[0m\n",
      "\u001b[34m[572]#011train-logloss:0.26916#011validation-logloss:0.30549\u001b[0m\n",
      "\u001b[34m[573]#011train-logloss:0.26916#011validation-logloss:0.30550\u001b[0m\n",
      "\u001b[34m[574]#011train-logloss:0.26915#011validation-logloss:0.30547\u001b[0m\n",
      "\u001b[34m[575]#011train-logloss:0.26915#011validation-logloss:0.30547\u001b[0m\n",
      "\u001b[34m[576]#011train-logloss:0.26915#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[577]#011train-logloss:0.26916#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[578]#011train-logloss:0.26916#011validation-logloss:0.30544\u001b[0m\n",
      "\u001b[34m[579]#011train-logloss:0.26916#011validation-logloss:0.30543\u001b[0m\n",
      "\u001b[34m[580]#011train-logloss:0.26913#011validation-logloss:0.30541\u001b[0m\n",
      "\u001b[34m[581]#011train-logloss:0.26913#011validation-logloss:0.30541\u001b[0m\n",
      "\u001b[34m[582]#011train-logloss:0.26913#011validation-logloss:0.30541\u001b[0m\n",
      "\u001b[34m[583]#011train-logloss:0.26904#011validation-logloss:0.30537\u001b[0m\n",
      "\u001b[34m[584]#011train-logloss:0.26904#011validation-logloss:0.30537\u001b[0m\n",
      "\u001b[34m[585]#011train-logloss:0.26897#011validation-logloss:0.30530\u001b[0m\n",
      "\u001b[34m[586]#011train-logloss:0.26897#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[587]#011train-logloss:0.26897#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[588]#011train-logloss:0.26897#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[589]#011train-logloss:0.26897#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[590]#011train-logloss:0.26890#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[591]#011train-logloss:0.26890#011validation-logloss:0.30555\u001b[0m\n",
      "\u001b[34m[592]#011train-logloss:0.26887#011validation-logloss:0.30544\u001b[0m\n",
      "\u001b[34m[593]#011train-logloss:0.26887#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[594]#011train-logloss:0.26881#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[595]#011train-logloss:0.26881#011validation-logloss:0.30532\u001b[0m\n",
      "\u001b[34m[596]#011train-logloss:0.26881#011validation-logloss:0.30533\u001b[0m\n",
      "\u001b[34m[597]#011train-logloss:0.26881#011validation-logloss:0.30531\u001b[0m\n",
      "\u001b[34m[598]#011train-logloss:0.26877#011validation-logloss:0.30525\u001b[0m\n",
      "\u001b[34m[599]#011train-logloss:0.26873#011validation-logloss:0.30528\u001b[0m\n",
      "\u001b[34m[600]#011train-logloss:0.26864#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[601]#011train-logloss:0.26864#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[602]#011train-logloss:0.26864#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[603]#011train-logloss:0.26864#011validation-logloss:0.30547\u001b[0m\n",
      "\u001b[34m[604]#011train-logloss:0.26864#011validation-logloss:0.30548\u001b[0m\n",
      "\u001b[34m[605]#011train-logloss:0.26864#011validation-logloss:0.30552\u001b[0m\n",
      "\u001b[34m[606]#011train-logloss:0.26864#011validation-logloss:0.30549\u001b[0m\n",
      "\u001b[34m[607]#011train-logloss:0.26864#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[608]#011train-logloss:0.26864#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[609]#011train-logloss:0.26864#011validation-logloss:0.30551\u001b[0m\n",
      "\u001b[34m[610]#011train-logloss:0.26854#011validation-logloss:0.30560\u001b[0m\n",
      "\u001b[34m[611]#011train-logloss:0.26847#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[612]#011train-logloss:0.26847#011validation-logloss:0.30545\u001b[0m\n",
      "\u001b[34m[613]#011train-logloss:0.26847#011validation-logloss:0.30542\u001b[0m\n",
      "\u001b[34m[614]#011train-logloss:0.26847#011validation-logloss:0.30544\u001b[0m\n",
      "\u001b[34m[615]#011train-logloss:0.26847#011validation-logloss:0.30543\u001b[0m\n",
      "\u001b[34m[616]#011train-logloss:0.26847#011validation-logloss:0.30542\u001b[0m\n",
      "\u001b[34m[617]#011train-logloss:0.26847#011validation-logloss:0.30544\u001b[0m\n",
      "\u001b[34m[618]#011train-logloss:0.26847#011validation-logloss:0.30543\u001b[0m\n",
      "\u001b[34m[619]#011train-logloss:0.26847#011validation-logloss:0.30546\u001b[0m\n",
      "\u001b[34m[620]#011train-logloss:0.26844#011validation-logloss:0.30562\u001b[0m\n",
      "\u001b[34m[621]#011train-logloss:0.26834#011validation-logloss:0.30564\u001b[0m\n",
      "\u001b[34m[622]#011train-logloss:0.26835#011validation-logloss:0.30566\u001b[0m\n",
      "\u001b[34m[623]#011train-logloss:0.26834#011validation-logloss:0.30563\u001b[0m\n",
      "\u001b[34m[624]#011train-logloss:0.26834#011validation-logloss:0.30563\u001b[0m\n",
      "\u001b[34m[625]#011train-logloss:0.26822#011validation-logloss:0.30578\u001b[0m\n",
      "\u001b[34m[626]#011train-logloss:0.26822#011validation-logloss:0.30579\u001b[0m\n",
      "\u001b[34m[627]#011train-logloss:0.26817#011validation-logloss:0.30581\u001b[0m\n",
      "\u001b[34m[628]#011train-logloss:0.26818#011validation-logloss:0.30581\u001b[0m\n",
      "\u001b[34m[629]#011train-logloss:0.26812#011validation-logloss:0.30598\u001b[0m\n",
      "\u001b[34m[630]#011train-logloss:0.26812#011validation-logloss:0.30596\u001b[0m\n",
      "\u001b[34m[631]#011train-logloss:0.26812#011validation-logloss:0.30595\u001b[0m\n",
      "\u001b[34m[632]#011train-logloss:0.26804#011validation-logloss:0.30609\u001b[0m\n",
      "\u001b[34m[633]#011train-logloss:0.26804#011validation-logloss:0.30609\u001b[0m\n",
      "\u001b[34m[634]#011train-logloss:0.26795#011validation-logloss:0.30637\u001b[0m\n",
      "\u001b[34m[635]#011train-logloss:0.26795#011validation-logloss:0.30635\u001b[0m\n",
      "\u001b[34m[636]#011train-logloss:0.26795#011validation-logloss:0.30637\u001b[0m\n",
      "\u001b[34m[637]#011train-logloss:0.26791#011validation-logloss:0.30628\u001b[0m\n",
      "\u001b[34m[638]#011train-logloss:0.26791#011validation-logloss:0.30629\u001b[0m\n",
      "\u001b[34m[639]#011train-logloss:0.26791#011validation-logloss:0.30628\u001b[0m\n",
      "\u001b[34m[640]#011train-logloss:0.26786#011validation-logloss:0.30656\u001b[0m\n",
      "\u001b[34m[641]#011train-logloss:0.26784#011validation-logloss:0.30660\u001b[0m\n",
      "\u001b[34m[642]#011train-logloss:0.26784#011validation-logloss:0.30661\u001b[0m\n",
      "\u001b[34m[643]#011train-logloss:0.26784#011validation-logloss:0.30661\u001b[0m\n",
      "\u001b[34m[644]#011train-logloss:0.26784#011validation-logloss:0.30660\u001b[0m\n",
      "\u001b[34m[645]#011train-logloss:0.26784#011validation-logloss:0.30660\u001b[0m\n",
      "\u001b[34m[646]#011train-logloss:0.26784#011validation-logloss:0.30662\u001b[0m\n",
      "\u001b[34m[647]#011train-logloss:0.26775#011validation-logloss:0.30685\u001b[0m\n",
      "\u001b[34m[648]#011train-logloss:0.26775#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[649]#011train-logloss:0.26775#011validation-logloss:0.30683\u001b[0m\n",
      "\u001b[34m[650]#011train-logloss:0.26775#011validation-logloss:0.30683\u001b[0m\n",
      "\u001b[34m[651]#011train-logloss:0.26775#011validation-logloss:0.30683\u001b[0m\n",
      "\u001b[34m[652]#011train-logloss:0.26775#011validation-logloss:0.30685\u001b[0m\n",
      "\u001b[34m[653]#011train-logloss:0.26775#011validation-logloss:0.30685\u001b[0m\n",
      "\u001b[34m[654]#011train-logloss:0.26775#011validation-logloss:0.30686\u001b[0m\n",
      "\u001b[34m[655]#011train-logloss:0.26775#011validation-logloss:0.30683\u001b[0m\n",
      "\u001b[34m[656]#011train-logloss:0.26775#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[657]#011train-logloss:0.26775#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[658]#011train-logloss:0.26775#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[659]#011train-logloss:0.26775#011validation-logloss:0.30686\u001b[0m\n",
      "\u001b[34m[660]#011train-logloss:0.26775#011validation-logloss:0.30688\u001b[0m\n",
      "\u001b[34m[661]#011train-logloss:0.26775#011validation-logloss:0.30687\u001b[0m\n",
      "\u001b[34m[662]#011train-logloss:0.26775#011validation-logloss:0.30685\u001b[0m\n",
      "\u001b[34m[663]#011train-logloss:0.26775#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[664]#011train-logloss:0.26775#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[665]#011train-logloss:0.26775#011validation-logloss:0.30685\u001b[0m\n",
      "\u001b[34m[666]#011train-logloss:0.26772#011validation-logloss:0.30673\u001b[0m\n",
      "\u001b[34m[667]#011train-logloss:0.26768#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[668]#011train-logloss:0.26768#011validation-logloss:0.30681\u001b[0m\n",
      "\u001b[34m[669]#011train-logloss:0.26768#011validation-logloss:0.30683\u001b[0m\n",
      "\u001b[34m[670]#011train-logloss:0.26756#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[671]#011train-logloss:0.26750#011validation-logloss:0.30687\u001b[0m\n",
      "\u001b[34m[672]#011train-logloss:0.26750#011validation-logloss:0.30686\u001b[0m\n",
      "\u001b[34m[673]#011train-logloss:0.26750#011validation-logloss:0.30686\u001b[0m\n",
      "\u001b[34m[674]#011train-logloss:0.26743#011validation-logloss:0.30681\u001b[0m\n",
      "\u001b[34m[675]#011train-logloss:0.26731#011validation-logloss:0.30692\u001b[0m\n",
      "\u001b[34m[676]#011train-logloss:0.26731#011validation-logloss:0.30694\u001b[0m\n",
      "\u001b[34m[677]#011train-logloss:0.26731#011validation-logloss:0.30692\u001b[0m\n",
      "\u001b[34m[678]#011train-logloss:0.26725#011validation-logloss:0.30686\u001b[0m\n",
      "\u001b[34m[679]#011train-logloss:0.26725#011validation-logloss:0.30689\u001b[0m\n",
      "\u001b[34m[680]#011train-logloss:0.26720#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[681]#011train-logloss:0.26720#011validation-logloss:0.30684\u001b[0m\n",
      "\u001b[34m[682]#011train-logloss:0.26720#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[683]#011train-logloss:0.26720#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[684]#011train-logloss:0.26720#011validation-logloss:0.30681\u001b[0m\n",
      "\u001b[34m[685]#011train-logloss:0.26720#011validation-logloss:0.30682\u001b[0m\n",
      "\u001b[34m[686]#011train-logloss:0.26720#011validation-logloss:0.30678\u001b[0m\n",
      "\u001b[34m[687]#011train-logloss:0.26720#011validation-logloss:0.30680\u001b[0m\n",
      "\u001b[34m[688]#011train-logloss:0.26720#011validation-logloss:0.30679\u001b[0m\n",
      "\u001b[34m[689]#011train-logloss:0.26717#011validation-logloss:0.30676\u001b[0m\n",
      "\u001b[34m[690]#011train-logloss:0.26717#011validation-logloss:0.30676\u001b[0m\n",
      "\u001b[34m[691]#011train-logloss:0.26718#011validation-logloss:0.30674\u001b[0m\n",
      "\u001b[34m[692]#011train-logloss:0.26718#011validation-logloss:0.30675\u001b[0m\n",
      "\u001b[34m[693]#011train-logloss:0.26717#011validation-logloss:0.30675\u001b[0m\n",
      "\u001b[34m[694]#011train-logloss:0.26717#011validation-logloss:0.30675\u001b[0m\n",
      "\u001b[34m[695]#011train-logloss:0.26711#011validation-logloss:0.30671\u001b[0m\n",
      "\u001b[34m[696]#011train-logloss:0.26711#011validation-logloss:0.30677\u001b[0m\n",
      "\u001b[34m[697]#011train-logloss:0.26711#011validation-logloss:0.30678\u001b[0m\n",
      "\u001b[34m[698]#011train-logloss:0.26711#011validation-logloss:0.30678\u001b[0m\n",
      "\u001b[34m[699]#011train-logloss:0.26711#011validation-logloss:0.30680\u001b[0m\n",
      "\u001b[34m[700]#011train-logloss:0.26711#011validation-logloss:0.30681\u001b[0m\n",
      "\u001b[34m[701]#011train-logloss:0.26711#011validation-logloss:0.30679\u001b[0m\n",
      "\u001b[34m[702]#011train-logloss:0.26711#011validation-logloss:0.30679\u001b[0m\n",
      "\u001b[34m[703]#011train-logloss:0.26711#011validation-logloss:0.30681\u001b[0m\n",
      "\u001b[34m[704]#011train-logloss:0.26711#011validation-logloss:0.30680\u001b[0m\n",
      "\u001b[34m[705]#011train-logloss:0.26700#011validation-logloss:0.30691\u001b[0m\n",
      "\u001b[34m[706]#011train-logloss:0.26698#011validation-logloss:0.30695\u001b[0m\n",
      "\u001b[34m[707]#011train-logloss:0.26696#011validation-logloss:0.30703\u001b[0m\n",
      "\u001b[34m[708]#011train-logloss:0.26696#011validation-logloss:0.30703\u001b[0m\n",
      "\u001b[34m[709]#011train-logloss:0.26696#011validation-logloss:0.30705\u001b[0m\n",
      "\u001b[34m[710]#011train-logloss:0.26685#011validation-logloss:0.30679\u001b[0m\n",
      "\u001b[34m[711]#011train-logloss:0.26674#011validation-logloss:0.30699\u001b[0m\n",
      "\u001b[34m[712]#011train-logloss:0.26674#011validation-logloss:0.30698\u001b[0m\n",
      "\u001b[34m[713]#011train-logloss:0.26674#011validation-logloss:0.30699\u001b[0m\n",
      "\u001b[34m[714]#011train-logloss:0.26674#011validation-logloss:0.30699\u001b[0m\n",
      "\u001b[34m[715]#011train-logloss:0.26671#011validation-logloss:0.30714\u001b[0m\n",
      "\u001b[34m[716]#011train-logloss:0.26671#011validation-logloss:0.30711\u001b[0m\n",
      "\u001b[34m[717]#011train-logloss:0.26671#011validation-logloss:0.30710\u001b[0m\n",
      "\u001b[34m[718]#011train-logloss:0.26663#011validation-logloss:0.30725\u001b[0m\n",
      "\u001b[34m[719]#011train-logloss:0.26663#011validation-logloss:0.30726\u001b[0m\n",
      "\u001b[34m[720]#011train-logloss:0.26661#011validation-logloss:0.30721\u001b[0m\n",
      "\u001b[34m[721]#011train-logloss:0.26651#011validation-logloss:0.30742\u001b[0m\n",
      "\u001b[34m[722]#011train-logloss:0.26647#011validation-logloss:0.30736\u001b[0m\n",
      "\u001b[34m[723]#011train-logloss:0.26648#011validation-logloss:0.30739\u001b[0m\n",
      "\u001b[34m[724]#011train-logloss:0.26640#011validation-logloss:0.30727\u001b[0m\n",
      "\u001b[34m[725]#011train-logloss:0.26637#011validation-logloss:0.30706\u001b[0m\n",
      "\u001b[34m[726]#011train-logloss:0.26637#011validation-logloss:0.30704\u001b[0m\n",
      "\u001b[34m[727]#011train-logloss:0.26637#011validation-logloss:0.30704\u001b[0m\n",
      "\u001b[34m[728]#011train-logloss:0.26638#011validation-logloss:0.30702\u001b[0m\n",
      "\u001b[34m[729]#011train-logloss:0.26637#011validation-logloss:0.30704\u001b[0m\n",
      "\u001b[34m[730]#011train-logloss:0.26637#011validation-logloss:0.30704\u001b[0m\n",
      "\u001b[34m[731]#011train-logloss:0.26632#011validation-logloss:0.30714\u001b[0m\n",
      "\u001b[34m[732]#011train-logloss:0.26624#011validation-logloss:0.30755\u001b[0m\n",
      "\u001b[34m[733]#011train-logloss:0.26624#011validation-logloss:0.30756\u001b[0m\n",
      "\u001b[34m[734]#011train-logloss:0.26619#011validation-logloss:0.30764\u001b[0m\n",
      "\u001b[34m[735]#011train-logloss:0.26619#011validation-logloss:0.30764\u001b[0m\n",
      "\u001b[34m[736]#011train-logloss:0.26619#011validation-logloss:0.30764\u001b[0m\n",
      "\u001b[34m[737]#011train-logloss:0.26619#011validation-logloss:0.30762\u001b[0m\n",
      "\u001b[34m[738]#011train-logloss:0.26614#011validation-logloss:0.30771\u001b[0m\n",
      "\u001b[34m[739]#011train-logloss:0.26614#011validation-logloss:0.30768\u001b[0m\n",
      "\u001b[34m[740]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[741]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[742]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[743]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[744]#011train-logloss:0.26614#011validation-logloss:0.30768\u001b[0m\n",
      "\u001b[34m[745]#011train-logloss:0.26614#011validation-logloss:0.30768\u001b[0m\n",
      "\u001b[34m[746]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[747]#011train-logloss:0.26614#011validation-logloss:0.30767\u001b[0m\n",
      "\u001b[34m[748]#011train-logloss:0.26601#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[749]#011train-logloss:0.26601#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[750]#011train-logloss:0.26598#011validation-logloss:0.30788\u001b[0m\n",
      "\u001b[34m[751]#011train-logloss:0.26598#011validation-logloss:0.30790\u001b[0m\n",
      "\u001b[34m[752]#011train-logloss:0.26598#011validation-logloss:0.30791\u001b[0m\n",
      "\u001b[34m[753]#011train-logloss:0.26598#011validation-logloss:0.30788\u001b[0m\n",
      "\u001b[34m[754]#011train-logloss:0.26592#011validation-logloss:0.30780\u001b[0m\n",
      "\u001b[34m[755]#011train-logloss:0.26588#011validation-logloss:0.30803\u001b[0m\n",
      "\u001b[34m[756]#011train-logloss:0.26584#011validation-logloss:0.30787\u001b[0m\n",
      "\u001b[34m[757]#011train-logloss:0.26584#011validation-logloss:0.30787\u001b[0m\n",
      "\u001b[34m[758]#011train-logloss:0.26582#011validation-logloss:0.30790\u001b[0m\n",
      "\u001b[34m[759]#011train-logloss:0.26578#011validation-logloss:0.30792\u001b[0m\n",
      "\u001b[34m[760]#011train-logloss:0.26573#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[761]#011train-logloss:0.26571#011validation-logloss:0.30772\u001b[0m\n",
      "\u001b[34m[762]#011train-logloss:0.26571#011validation-logloss:0.30771\u001b[0m\n",
      "\u001b[34m[763]#011train-logloss:0.26570#011validation-logloss:0.30773\u001b[0m\n",
      "\u001b[34m[764]#011train-logloss:0.26566#011validation-logloss:0.30781\u001b[0m\n",
      "\u001b[34m[765]#011train-logloss:0.26560#011validation-logloss:0.30771\u001b[0m\n",
      "\u001b[34m[766]#011train-logloss:0.26561#011validation-logloss:0.30776\u001b[0m\n",
      "\u001b[34m[767]#011train-logloss:0.26561#011validation-logloss:0.30778\u001b[0m\n",
      "\u001b[34m[768]#011train-logloss:0.26561#011validation-logloss:0.30779\u001b[0m\n",
      "\u001b[34m[769]#011train-logloss:0.26561#011validation-logloss:0.30777\u001b[0m\n",
      "\u001b[34m[770]#011train-logloss:0.26557#011validation-logloss:0.30801\u001b[0m\n",
      "\u001b[34m[771]#011train-logloss:0.26553#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[772]#011train-logloss:0.26553#011validation-logloss:0.30795\u001b[0m\n",
      "\u001b[34m[773]#011train-logloss:0.26553#011validation-logloss:0.30792\u001b[0m\n",
      "\u001b[34m[774]#011train-logloss:0.26545#011validation-logloss:0.30773\u001b[0m\n",
      "\u001b[34m[775]#011train-logloss:0.26545#011validation-logloss:0.30773\u001b[0m\n",
      "\u001b[34m[776]#011train-logloss:0.26539#011validation-logloss:0.30770\u001b[0m\n",
      "\u001b[34m[777]#011train-logloss:0.26539#011validation-logloss:0.30768\u001b[0m\n",
      "\u001b[34m[778]#011train-logloss:0.26535#011validation-logloss:0.30789\u001b[0m\n",
      "\u001b[34m[779]#011train-logloss:0.26535#011validation-logloss:0.30790\u001b[0m\n",
      "\u001b[34m[780]#011train-logloss:0.26535#011validation-logloss:0.30791\u001b[0m\n",
      "\u001b[34m[781]#011train-logloss:0.26534#011validation-logloss:0.30802\u001b[0m\n",
      "\u001b[34m[782]#011train-logloss:0.26534#011validation-logloss:0.30802\u001b[0m\n",
      "\u001b[34m[783]#011train-logloss:0.26534#011validation-logloss:0.30800\u001b[0m\n",
      "\u001b[34m[784]#011train-logloss:0.26534#011validation-logloss:0.30801\u001b[0m\n",
      "\u001b[34m[785]#011train-logloss:0.26534#011validation-logloss:0.30800\u001b[0m\n",
      "\u001b[34m[786]#011train-logloss:0.26534#011validation-logloss:0.30800\u001b[0m\n",
      "\u001b[34m[787]#011train-logloss:0.26534#011validation-logloss:0.30799\u001b[0m\n",
      "\u001b[34m[788]#011train-logloss:0.26534#011validation-logloss:0.30799\u001b[0m\n",
      "\u001b[34m[789]#011train-logloss:0.26526#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[790]#011train-logloss:0.26526#011validation-logloss:0.30794\u001b[0m\n",
      "\u001b[34m[791]#011train-logloss:0.26526#011validation-logloss:0.30793\u001b[0m\n",
      "\u001b[34m[792]#011train-logloss:0.26526#011validation-logloss:0.30795\u001b[0m\n",
      "\u001b[34m[793]#011train-logloss:0.26526#011validation-logloss:0.30793\u001b[0m\n",
      "\u001b[34m[794]#011train-logloss:0.26526#011validation-logloss:0.30795\u001b[0m\n",
      "\u001b[34m[795]#011train-logloss:0.26520#011validation-logloss:0.30788\u001b[0m\n",
      "\u001b[34m[796]#011train-logloss:0.26520#011validation-logloss:0.30788\u001b[0m\n",
      "\u001b[34m[797]#011train-logloss:0.26520#011validation-logloss:0.30787\u001b[0m\n",
      "\u001b[34m[798]#011train-logloss:0.26520#011validation-logloss:0.30786\u001b[0m\n",
      "\u001b[34m[799]#011train-logloss:0.26520#011validation-logloss:0.30787\u001b[0m\n",
      "\n",
      "2025-07-17 10:45:36 Uploading - Uploading generated training model\n",
      "2025-07-17 10:45:36 Completed - Training job completed\n",
      "Training seconds: 106\n",
      "Billable seconds: 106\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(\n",
    "    {\n",
    "        \"train\": train_input,\n",
    "        \"validation\": validation_input\n",
    "    },\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** While the above cell runs, follow the below steps to monitor the progress of the training job: \n",
    "\n",
    "1. Navigate to the AWS console and on the top-left search bar, search for Amazon SageMaker AI\n",
    "\n",
    "2. In the SageMaker AI console, on the left pane, select **Training** and then select **Training jobs**.  \n",
    "\n",
    "3. Choose the link for the training job that starts with **sagemaker-xgboost** job to monitor the job creation progress.\n",
    "\n",
    "4. Wait until the job status changes from **InProgress** to **Completed**. This indicates that the job creation is complete. The processing may take up to 5 minutes.\n",
    "\n",
    "5. If the job status shows as **Failed**, re-run the above code cell and wait until the job status changes from **InProgress** to **Completed**.\n",
    "\n",
    "6. Once the processing job status changes to **Completed**, return to the notebook to proceed with the next tasks.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-exclamation-circle\" style=\"color:#7C5AED\"></i> **Caution:** Do not run the next code cell until the processing job completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-clipboard-check\" style=\"color:#18ab4b\"></i> **Expected output:** If the estimator and hyperparameter configuration are correct and the training job is started correctly, you should see the following output:\n",
    "\n",
    "```plain\n",
    "************************\n",
    "**** EXAMPLE OUTPUT ****\n",
    "************************\n",
    "\n",
    "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-08-09-20-09-56-628\n",
    "2023-08-09 20:09:56 Starting - Starting the training job...\n",
    "2023-08-09 20:10:19 Starting - Preparing the instances for trainingCreateXgboostReport: InProgress\n",
    "......\n",
    "2023-08-09 20:11:21 Downloading - Downloading input data...\n",
    "2023-08-09 20:11:55 Training - Downloading the training image...\n",
    "2023-08-09 20:12:20 Training - Training image download completed. Training in progress....\n",
    "2023-08-09 20:12:56 Uploading - Uploading generated training model...\n",
    "2023-08-09 20:13:20 Completed - Training job completed\n",
    "..Training seconds: 107\n",
    "Billable seconds: 107\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define the S3 location where the XGBoost report notebook is hosted, a path construction process is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:54.448341Z",
     "iopub.status.busy": "2025-07-17T10:48:54.448057Z",
     "iopub.status.idle": "2025-07-17T10:48:54.452386Z",
     "shell.execute_reply": "2025-07-17T10:48:54.451751Z",
     "shell.execute_reply.started": "2025-07-17T10:48:54.448319Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket, project_prefix = xgb_model.output_path[5:].split('/',1)\n",
    "rule_output_prefix = project_prefix + \"/\" + xgb_model.latest_training_job.job_name + \"/rule-output/CreateXgboostReport/xgboost_report.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure timely access to the XGBoost report generated by the SageMaker Debugger, a waiter function is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:02.480724Z",
     "iopub.status.busy": "2025-07-17T10:49:02.480131Z",
     "iopub.status.idle": "2025-07-17T10:49:02.566384Z",
     "shell.execute_reply": "2025-07-17T10:49:02.565453Z",
     "shell.execute_reply.started": "2025-07-17T10:49:02.480694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the report to become available\n",
      "The report is now available!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Waiting for the report to become available\")\n",
    "\n",
    "waiter = boto3.client('s3').get_waiter('object_exists')\n",
    "\n",
    "waiter.wait(\n",
    "    Bucket=bucket,\n",
    "    Key=rule_output_prefix,\n",
    "    WaiterConfig={\n",
    "        'Delay': 15,\n",
    "        'MaxAttempts': 60\n",
    "    }\n",
    ")\n",
    "\n",
    "print('The report is now available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5: Evaluate a model\n",
    "\n",
    "After the training job has completed, you can download an XGBoost training report generated by SageMaker Debugger. The XGBoost training report offers you insights into the training progress and results, such as the loss function with respect to iteration, feature importance, confusion matrix, accuracy curves, and other statistical results of training. \n",
    "\n",
    "For SageMaker XGBoost training jobs, use the Debugger `CreateXgboostReport` rule to receive a comprehensive training report of the training progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:08.975750Z",
     "iopub.status.busy": "2025-07-17T10:49:08.975391Z",
     "iopub.status.idle": "2025-07-17T10:49:11.905624Z",
     "shell.execute_reply": "2025-07-17T10:49:11.904592Z",
     "shell.execute_reply.started": "2025-07-17T10:49:08.975728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "rule_output_path = xgb_model.output_path + \"/\" + xgb_model.latest_training_job.job_name + \"/rule-output\"\n",
    "! aws s3 ls {rule_output_path} --recursive\n",
    "! aws s3 cp {rule_output_path} ./ --recursive\n",
    "! aws s3 cp {'s3://{}/{}'.format(bucket, rule_output_prefix)} ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link in the output of the next cell opens a new tab in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_2.ipynb** tab to the side or choose the **lab_2.ipynb** tab, and then from the toolbar, select **File** and **New View for Notebook**. You can now have the directions displayed as you explore the XGBoost report.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions. When you are finished exploring the XGBoost report, return to the notebook by choosing the **lab_2.ipynb** tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:15.827768Z",
     "iopub.status.busy": "2025-07-17T10:49:15.827449Z",
     "iopub.status.idle": "2025-07-17T10:49:15.837036Z",
     "shell.execute_reply": "2025-07-17T10:49:15.836292Z",
     "shell.execute_reply.started": "2025-07-17T10:49:15.827744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Click link below to view the XGBoost Training notebook'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='CreateXgboostReport/xgboost_report.ipynb' target='_blank'>CreateXgboostReport/xgboost_report.ipynb</a><br>"
      ],
      "text/plain": [
       "/home/sagemaker-user/CreateXgboostReport/xgboost_report.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Click link below to view the XGBoost Training notebook\", FileLink(\"CreateXgboostReport/xgboost_report.ipynb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** After you run this code, you should see the following output: **'Click link below to view the XGBoost Training notebook' <span style=\"ssb_sm_blue\">CreateXgboostReport/xgboost_report.ipynb</span>**\n",
    "\n",
    "To open the notebook in a new tab, choose the link. \n",
    "\n",
    "<!-- When the notebook opens, in the **Set up notebook environment** window, configure the following:\n",
    "\n",
    "- For **Image**, choose **Data Science 3.0**.\n",
    "- For **Kernel**, choose **Python 3**.\n",
    "- Choose **Select**. -->\n",
    "\n",
    "At the top of the **xgboost_report.ipynb** tab, choose the <i aria-hidden=\"true\" class=\"fas fa-forward\"></i> **Restart the kernel and run all cells** button. When prompted with **Restart Kernel?**, choose **Restart**.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** It takes approximately 2â€“3 minutes to run all of the cells.\n",
    "\n",
    "When all cells have finished running, scroll down until you make it to the **Confusion Matrix**. The confusion matrix illustrates in a table the number of correct and incorrect predictions for each class by comparing an observation's predicted class and its true class. When you go to the diagram you see **true positive (TP)**, **true negative (TN)**, **false positive (FP)**, and **false negative (FN)** values.\n",
    "\n",
    "- **True positive:** If the actual classification is positive and the predicted classification is positive (1,1), this is called a **true positive (TP)** result because the positive sample was correctly identified by the classifier. \n",
    "- **False negative:** If the actual classification is positive and the predicted classification is negative (1,0), this is called a **false negative (FN)** result because the positive sample is incorrectly identified by the classifier as being negative. \n",
    "- **False positive:** If the actual classification is negative and the predicted classification is positive (0,1), this is called a **false positive (FP)** result because the negative sample is incorrectly identified by the classifier as being positive. \n",
    "- **True negative**: If the actual classification is negative and the predicted classification is negative (0,0), this is called a **true negative (TN)** result because the negative sample gets correctly identified by the classifier.\n",
    "\n",
    "Next, scroll down to **Evaluation of the Confusion Matrix** and take a closer look at the **Classification report** to understand the summary of the precision, recall, and F1-score for each class.\n",
    "\n",
    "- **Precision**: Measures the fraction of actual positives that were predicted as positives out of all of those predicted as positive. The range is 0 to 1, and a larger value indicates better accuracy. Precision expresses the proportion of the data points that your model says was relevant and that were actually relevant. Precision is a good measure to consider, especially when the costs of FP are high.\n",
    "- **Recall/Sensitivity/True Positive Rate (TPR)**: Measures the fraction of actual positives that were predicted as positives. The range is also 0 to 1, and a larger value indicates a better predictive accuracy. This is also known as Recall/Sensitivity. This measure expresses the ability to find all the relevant instances in a dataset.\n",
    "- **F1-Score**: Demonstrates your target metric, which is the harmonic mean of precision and recall. F1 takes both FP and FN into account to give the same weight to precision and recall.\n",
    "\n",
    "You are trying to predict if people make less than 50,000 USD so you can promote government assistance services to qualified citizens. In this case, the F1-Score is a good measure to use because it takes FP (people who make over 50,000 USD who were labeled as making less than 50,000 USD) and FN (people who make under 50,000 USD who were labeled as making more than 50,000 USD) into account. You want to make sure that your precision and recall are both high, and the F1-Score takes both measures into account. In the next lab, you optimize the model by tuning the hyperparameters to see if you can get a higher F1-Score.\n",
    "\n",
    "What are the **Precision**, **Recall**, **F1-Score**, and **Overall Accuracy** for this model?\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"far fa-comment\" style=\"color:#008296\"></i> **Consider:** Take a moment to review the other graphs that are included in the notebook. What kind of information do you see? What might be helpful to you when training your own models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6: View the model artifacts\n",
    "\n",
    "SageMaker AI stores the model artifact in your S3 bucket. To find the location of the model artifact, follow these steps:\n",
    "\n",
    "<!-- 1. Navigate to the AWS Management Console.\n",
    "\n",
    "1. At the top of the AWS Management Console, in the search bar, search for and choose `S3`.\n",
    "\n",
    "1. In the list of buckets, choose the Amazon S3 bucket that contains **labdatabucket** in its name.\n",
    "\n",
    "1. Navigate to the **scripts/data/output/sagemaker-xgboost-.../output** subfolder.  -->\n",
    "\n",
    "1. Choose the bucket icon from the left menu bar.\n",
    "\n",
    "1. In the list of buckets, open the Amazon S3 bucket that contains **labdatabucket** in its name.\n",
    "\n",
    "1. Navigate to the **scripts/data/output/ sagemaker-xgboost-.../output** subfolder. \n",
    "\n",
    "You see the model artifact **model.tar.gz** in the subfolder. This is the model that you created with your SageMaker Estimator by calling the fit() method.\n",
    "\n",
    "You viewed the model artifacts, including the model.tar.gz file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
