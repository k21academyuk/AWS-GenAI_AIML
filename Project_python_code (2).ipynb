{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code Explanation\n",
        "1)Connects to Amazon Bedrock (Knowledge Base/Agent service).\n",
        "\n",
        "2) Lists knowledge bases in your account (limited to 1).\n",
        "\n",
        "3) Prints the Knowledge Base ID if found.\n",
        "\n",
        "4) Otherwise, prints a message that no KBs exist.\n",
        "\n",
        "5) Handles API errors gracefully.\n",
        "\n",
        "This is typically the first step in a RAG workflow  confirming that your Bedrock Knowledge Base exists and retrieving its ID.\n",
        "\n",
        "# Details\n",
        "\n",
        "\n",
        "\n",
        "* boto3 ‚Üí AWS SDK for Python, used to interact with AWS services.\n",
        "* botocore ‚Üí low-level core library used by boto3, provides error handling, request/response handling.\n",
        "* Creates a Bedrock Agent client using bedrock-agent.\n",
        "\n",
        "This is the service namespace for interacting with Amazon Bedrock Knowledge Bases and Agents.\n"
      ],
      "metadata": {
        "id": "2mC4qeKEtlyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icaIOfqrs9Jd"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import botocore\n",
        "\n",
        "session = boto3.Session()\n",
        "bedrock_client = session.client('bedrock-agent')\n",
        "\n",
        "try:\n",
        "    response = bedrock_client.list_knowledge_bases(\n",
        "        maxResults=1  # We only need to retrieve the first Knowledge Base\n",
        "    )\n",
        "    knowledge_base_summaries = response.get('knowledgeBaseSummaries', [])\n",
        "\n",
        "    if knowledge_base_summaries:\n",
        "        kb_id = knowledge_base_summaries[0]['knowledgeBaseId']\n",
        "        print(f\"Knowledge Base ID: {kb_id}\")\n",
        "    else:\n",
        "        print(\"No Knowledge Base summaries found.\")\n",
        "\n",
        "except botocore.exceptions.ClientError as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "\n",
        "1. Prepares AWS session & region.\n",
        "2. Sets up a Bedrock Runtime client (for foundation model inference).\n",
        "3. Sets up a Bedrock Agent Runtime client (for RAG apps, knowledge base queries, or agent flows).\n",
        "4. Configures clients with long timeouts & no retries to handle potentially long-running calls.\n",
        "5. Includes a pretty printer for cleanly displaying responses.\n",
        "\n",
        "#Details\n",
        "\n",
        "* boto3 ‚Üí AWS SDK for Python (interacts with AWS services).\n",
        "* Config (from botocore.client) ‚Üí lets you customize client settings like timeouts and retries.\n",
        "* pprint ‚Üí pretty printer for nicer JSON/dict printing.\n",
        "* json ‚Üí standard Python library for working with JSON.\n",
        "* bedrock_client ‚Üí talk to foundation models directly.\n",
        "* bedrock_agent_client ‚Üí talk to knowledge bases / RAG agents.\n"
      ],
      "metadata": {
        "id": "_6JXYBTSuZwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from botocore.client import Config\n",
        "import pprint\n",
        "import json\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "session = boto3.session.Session()\n",
        "region = session.region_name\n",
        "\n",
        "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
        "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
        "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
        "                              config=bedrock_config, region_name = region)\n"
      ],
      "metadata": {
        "id": "Oy7LIH3Euvh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sXgEVn2nuyLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "This function retrieves relevant context from your Knowledge Base using hybrid semantic + keyword search to support your RAG QA pipeline.\n"
      ],
      "metadata": {
        "id": "6yMeI-5R_nE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, kbId, numberOfResults=5):\n",
        "    return bedrock_agent_client.retrieve(\n",
        "        retrievalQuery= {\n",
        "            'text': query\n",
        "        },\n",
        "        knowledgeBaseId=kbId,\n",
        "        retrievalConfiguration= {\n",
        "            'vectorSearchConfiguration': {\n",
        "                'numberOfResults': numberOfResults,\n",
        "                'overrideSearchType': \"HYBRID\", # optional\n",
        "            }\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "VukaC3K3_pp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Explanation\n",
        "1. User asks: ‚ÄúWhat was the total operating lease liabilities and total sublease income ‚Ä¶ ?‚Äù\n",
        "2. Bedrock Knowledge Base searches across embedded vectors + keywords.\n",
        "3. Returns top 5 most relevant text chunks from your documents (financial reports in S3, indexed in OpenSearch).\n",
        "4. You now have retrieved context.\n",
        "5. Next step in RAG ‚Üí Pass this retrievalResults into a Bedrock LLM (e.g., Nova Pro) to generate a final answer.\n"
      ],
      "metadata": {
        "id": "zOEPO8TYABPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What was the total operating lease liabilities and total sublease income of the AnyCompany as of December 31, 2022?\"\n",
        "response = retrieve(query, kb_id, 5)\n",
        "retrievalResults = response['retrievalResults']\n",
        "pp.pprint(retrievalResults)"
      ],
      "metadata": {
        "id": "O5XG--VXAPhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "The function explanation,\n",
        "1. Take retrieval results ‚Üí input is the list of results returned from Knowledge Base search.\n",
        "2. Initialize an empty list ‚Üí contexts = [].\n",
        "3. Loop through results ‚Üí for each retrieved result (a dictionary with text + metadata + score).\n",
        "4. Extract only the text ‚Üí retrievedResult['content']['text'].\n",
        "5. Append text to list ‚Üí collect all chunks into contexts.\n",
        "6. Return the list of texts ‚Üí clean context chunks ready for LLM input.\n"
      ],
      "metadata": {
        "id": "hntZkdX_AVtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch context from the response\n",
        "def get_contexts(retrievalResults):\n",
        "    contexts = []\n",
        "    for retrievedResult in retrievalResults:\n",
        "        contexts.append(retrievedResult['content']['text'])\n",
        "    return contexts"
      ],
      "metadata": {
        "id": "YIWPKDBaAZ4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "\n",
        "This step verifies what knowledge (context text) has been retrieved from your S3 documents (via the Bedrock Knowledge Base + OpenSearch).\n",
        "Later, these contexts will be fed into the LLM (e.g., Nova Pro/Lite) as grounding context for the RAG answer.\n"
      ],
      "metadata": {
        "id": "hUubKAr1Bf4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = get_contexts(retrievalResults)\n",
        "pp.pprint(contexts)"
      ],
      "metadata": {
        "id": "2xgtnaTtB7v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "\n",
        "This is the prompt engineering step of your RAG pipeline.\n",
        "\n",
        "This prompt construction step is where you merge:\n",
        "\n",
        "ü°™ User Query (query)\n",
        "\n",
        "ü°™ Retrieved Context (contexts)\n",
        "\n",
        "ü°™ System Instructions (rules & guidelines)\n",
        "\n",
        "The result is a structured, context-grounded prompt that can be safely sent to the Bedrock LLM (bedrock-runtime) for generation."
      ],
      "metadata": {
        "id": "cHsJSlvUB8PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Human: You are a financial advisor AI system specializing in analyzing financial statements, particularly focusing on lease accounting and disclosures. Use the following pieces of information to provide a detailed answer to the question enclosed in <question> tags.\n",
        "\n",
        "When analyzing the information, please follow these guidelines:\n",
        "1. Look for specific details about operating lease liabilities and sublease income as of December 31, 2022.\n",
        "2. If exact figures for the requested date are not available, provide the most recent available data and clearly state the date.\n",
        "3. Include any relevant information about lease terms, weighted-average remaining lease terms, or lease accounting policies.\n",
        "4. If the information is not explicitly about AnyCompany, but general lease accounting information is provided, summarize that instead.\n",
        "5. If you don't find specific lease information, mention any other financial data that might be relevant to understanding the company's obligations or income streams.\n",
        "\n",
        "<context>\n",
        "{contexts}\n",
        "</context>\n",
        "\n",
        "<question>\n",
        "{query}\n",
        "</question>\n",
        "\n",
        "In your response:\n",
        "- Provide specific numerical figures where available, using proper currency notation (e.g., $X million).\n",
        "- Clearly indicate what information is directly from the context and what might be inferred.\n",
        "- If certain information is not available, explicitly state: \"The [specific detail] is not provided in the available financial statements.\"\n",
        "- Include any other relevant lease-related or financial information found in the context.\n",
        "\n",
        "Assistant:\"\"\""
      ],
      "metadata": {
        "id": "UVMCPCNGB8uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "\n",
        "You‚Äôre packaging the user‚Äôs structured prompt into the format Nova Lite expects, with generation controls, so you can send this payload to bedrock-runtime.invoke_model().\n"
      ],
      "metadata": {
        "id": "OOHH03tjB8_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# payload with model parameters\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{\"text\": prompt}]\n",
        "}]\n",
        "\n",
        "# Create the proper Nova Lite payload\n",
        "nova_payload = {\n",
        "    \"schemaVersion\": \"messages-v1\",\n",
        "    \"messages\": messages,\n",
        "    \"inferenceConfig\": {\n",
        "        \"maxTokens\": 512,\n",
        "        \"temperature\": 0.5,\n",
        "        \"topP\": 0.9,\n",
        "        \"topK\": 20\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Ga0FlXloB9S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code Explanation\n",
        "1. Pick model + formats\n",
        "2. Send payload with invoke_model()\n",
        "3. Parse JSON response\n",
        "4. Extract just the text reply\n",
        "5. Print it\n"
      ],
      "metadata": {
        "id": "8hvkKOvpB9f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelId = 'amazon.nova-lite-v1:0' # change this to use a different version from the model provider\n",
        "accept = 'application/json'\n",
        "contentType = 'application/json'\n",
        "\n",
        "response = bedrock_client.invoke_model(\n",
        "    body=json.dumps(nova_payload),\n",
        "    modelId=modelId,\n",
        "    accept=accept,\n",
        "    contentType=contentType\n",
        ")\n",
        "\n",
        "# Parse and extract the response\n",
        "response_body = json.loads(response.get('body').read())\n",
        "\n",
        "# Extract just the text from the response\n",
        "response_text = ''\n",
        "if 'output' in response_body and 'message' in response_body['output']:\n",
        "    message_content = response_body['output']['message']['content']\n",
        "    if message_content and isinstance(message_content, list):\n",
        "        response_text = message_content[0].get('text', '')\n",
        "\n",
        "# Print the response text\n",
        "print(response_text)"
      ],
      "metadata": {
        "id": "6TUx_d4VB91b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}