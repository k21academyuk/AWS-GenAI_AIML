{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b16781-7f33-4b2c-9495-7e2bc67dcd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: langsmith in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (0.4.43)\n",
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.0.7)\n",
      "Requirement already satisfied: chromadb in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.3.4)\n",
      "Requirement already satisfied: langchain-chroma in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain_community in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-aws in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (3.11.4)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (2.12.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langsmith) (0.4.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.38.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests>=2.0.0->langsmith) (1.26.20)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: boto3>=1.40.19 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-aws) (1.40.69)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.69 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.40.19->langchain-aws) (1.40.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.40.19->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.40.19->langchain-aws) (0.14.0)\n",
      "Requirement already satisfied: pyproject_hooks in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (1.1.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.20.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "‚úÖ Dependencies installed and environment configured successfully\n",
      "üîë LangSmith API key configured for tracing and monitoring\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INSTALL DEPENDENCIES AND SETUP ENVIRONMENT\n",
    "# =============================================================================\n",
    "\n",
    "# Upgrade pip to ensure we have the latest package manager\n",
    "! pip install --upgrade pip\n",
    "\n",
    "# Install required LangChain and AWS dependencies for our RAG system\n",
    "! pip install --upgrade langsmith langchain chromadb langchain-chroma langchain_community langchain-aws\n",
    "\n",
    "# Import os for environment variable management\n",
    "import os\n",
    "\n",
    "# Configure LangChain environment variables\n",
    "\n",
    "# Enable LangSmith tracing for monitoring and debugging (optional)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# Set your LangSmith project name for organizing runs\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-aching-poisoning-52\"\n",
    "\n",
    "# Add your LangSmith API key for authentication\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "\n",
    "print(\"‚úÖ Dependencies installed and environment configured successfully\")\n",
    "print(\"üîë LangSmith API key configured for tracing and monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e39f92-1d89-4038-b280-e371c42bbefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AWS Bedrock client initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE AWS BEDROCK CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "# Import boto3 for AWS service interactions\n",
    "import boto3\n",
    "\n",
    "# Define AWS region where Bedrock service is available\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# Create Bedrock runtime client to interact with foundation models\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",  # Service for invoking foundation models\n",
    "    region_name=AWS_REGION,           # AWS region\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AWS Bedrock client initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db46b24-1dad-473d-961b-836ab351bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized with Amazon Titan Text Express v1\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE LARGE LANGUAGE MODEL (LLM)\n",
    "# =============================================================================\n",
    "\n",
    "# Import BedrockLLM class from langchain_aws package\n",
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "# Initialize the LLM with the Amazon Titan Text Express model\n",
    "\n",
    "# This model will generate answers based on the retrieved context\n",
    "llm = BedrockLLM(\n",
    "    client=bedrock_client,           # Bedrock client from previous cell\n",
    "    model_id=\"amazon.titan-text-express-v1\"  # Amazon's powerful text generation model\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized with Amazon Titan Text Express v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb067905-4240-4809-8795-4998eccb4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2 documents from web sources\n",
      "üìÑ First document contains 32126 characters\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD DOCUMENTS FROM WEB SOURCES\n",
    "# =============================================================================\n",
    "\n",
    "# Import WebBaseLoader to fetch and parse web content\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Create loader instance with IBM documentation URLs about cloud computing and data science\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://www.ibm.com/think/topics/cloud-computing\",   # Cloud computing documentation\n",
    "        \"https://www.ibm.com/think/topics/data-science\"       # Data science documentation\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load documents from the web URLs\n",
    "docs = loader.load()\n",
    "\n",
    "# Display loading results\n",
    "print(f\"‚úÖ Loaded {len(docs)} documents from web sources\")\n",
    "print(f\"üìÑ First document contains {len(docs[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73282ffc-7784-4b90-b694-e6aca14365c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã DOCUMENT SOURCES:\n",
      "==================================================\n",
      "Document 1: https://www.ibm.com/think/topics/cloud-computing\n",
      "Document 2: https://www.ibm.com/think/topics/data-science\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INSPECT LOADED DOCUMENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìã DOCUMENT SOURCES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Loop through each loaded document and display its source\n",
    "for i, doc in enumerate(docs):\n",
    "    \n",
    "    # Extract source URL from document metadata\n",
    "    source = doc.metadata.get('source', 'N/A')\n",
    "    print(f\"Document {i+1}: {source}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e47c32-3365-45d3-8a96-25e927592f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DOCUMENT CONTENT PREVIEW:\n",
      "==================================================\n",
      "What Is Cloud Computing? | IBM What is cloud computing? Authors Stephanie Susnjara Staff Writer IBM Think Ian Smalley Staff Editor IBM Think What is cloud computing? Cloud computing is on-demand access to computing resources‚Äîphysical or virtual servers, data storage, networking capabilities, applica...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREVIEW DOCUMENT CONTENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîç DOCUMENT CONTENT PREVIEW:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clean the content by removing extra whitespace for better readability\n",
    "clean_content = ' '.join(docs[0].page_content.split())\n",
    "\n",
    "# Display first 300 characters of cleaned content as preview\n",
    "print(clean_content[:300] + \"...\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d48cd81-424d-477d-9bb4-53cb30666cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 167 text chunks from original documents\n",
      "   Chunk size: 500 chars, Overlap: 150 chars\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPLIT DOCUMENTS INTO TEXT CHUNKS\n",
    "# =============================================================================\n",
    "\n",
    "# Import text splitter to break large documents into manageable chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize text splitter with optimal settings for RAG systems\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,       # Maximum characters per chunk\n",
    "    chunk_overlap=150,    # Characters overlapping between chunks for context\n",
    "    add_start_index=True  # Track original position in source document\n",
    ")\n",
    "\n",
    "# Split all documents into smaller chunks\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"‚úÖ Created {len(all_splits)} text chunks from original documents\")\n",
    "print(\"   Chunk size: 500 chars, Overlap: 150 chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e15b52-d6ce-4683-b3ff-39af668ac73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù SAMPLE TEXT CHUNKS (First 3):\n",
      "==================================================\n",
      "üìÑ Split 1 (478 characters):\n",
      "What Is Cloud Computing? | IBM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "----------------------------------------\n",
      "üìÑ Split 2 (490 characters):\n",
      "Stephanie  Susnjara\n",
      "\n",
      "Staff Writer\n",
      "IBM Think\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ian Smalley\n",
      "\n",
      "Staff Editor\n",
      " IBM Think\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "----------------------------------------\n",
      "üìÑ Split 3 (282 characters):\n",
      "Think Newsletter\n",
      "\n",
      "\n",
      "\n",
      "Join over 100,000 subscribers who read the latest news in tech\n",
      "\n",
      "\n",
      "\n",
      "Stay up to dat...\n",
      "----------------------------------------\n",
      "... and 164 more chunks\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DISPLAY SAMPLE TEXT CHUNKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìù SAMPLE TEXT CHUNKS (First 3):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display first 3 chunks to verify splitting worked correctly\n",
    "for i, split in enumerate(all_splits[:3]):\n",
    "    print(f\"üìÑ Split {i+1} ({len(split.page_content)} characters):\")\n",
    "    \n",
    "    # Show first 100 characters of each chunk\n",
    "    print(split.page_content[:100] + \"...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"... and {len(all_splits) - 3} more chunks\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf719ef-a05f-42f7-b32f-715e6e20e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating vector store...\n",
      "‚úÖ Vector store created successfully!\n",
      "üìä Stored 334 document chunks\n",
      "üî§ Using Chroma's default all-MiniLM-L6-v2 embeddings\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE VECTOR STORE WITH CHROMADB\n",
    "# =============================================================================\n",
    "\n",
    "# Import Chroma vector store for semantic search capabilities\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "print(\"üîÑ Creating vector store...\")\n",
    "\n",
    "# Create Chroma vector store from document chunks\n",
    "\n",
    "# Chroma automatically uses its built-in sentence-transformers embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,          # Our text chunks\n",
    "    persist_directory=\"./chroma_db\" # Directory to store the vector database\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Vector store created successfully!\")\n",
    "print(f\"üìä Stored {vectorstore._collection.count()} document chunks\")\n",
    "print(\"üî§ Using Chroma's default all-MiniLM-L6-v2 embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30fc5ee-1bfc-48fe-bfca-d6c3ce0bd6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document retriever configured successfully!\n",
      "üîç Search type: similarity\n",
      "üìà Returning top 3 most relevant documents\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE DOCUMENT RETRIEVER\n",
    "# =============================================================================\n",
    "\n",
    "# Create a retriever that will find relevant documents for user questions\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # Use similarity search (cosine distance)\n",
    "    search_kwargs={\"k\": 3}     # Return top 3 most relevant documents\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Document retriever configured successfully!\")\n",
    "print(f\"üîç Search type: {retriever.search_type}\")\n",
    "print(f\"üìà Returning top {retriever.search_kwargs['k']} most relevant documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190b1655-f2cb-4d70-8fd3-08a2c605c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Building RAG chain...\n",
      "‚úÖ RAG chain built successfully!\n",
      "   Flow: Question ‚Üí Retriever ‚Üí Prompt ‚Üí LLM ‚Üí Answer\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BUILD RAG (RETRIEVAL-AUGMENTED GENERATION) CHAIN\n",
    "# =============================================================================\n",
    "\n",
    "# Import necessary components for building the RAG pipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"üîó Building RAG chain...\")\n",
    "\n",
    "# Define the prompt template that guides the LLM how to answer questions\n",
    "template = \"\"\"Answer the question based on the context below. Keep it concise.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Create prompt template from the defined structure\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Build the RAG chain that connects all components:\n",
    "# 1. Retrieve relevant documents based on question\n",
    "# 2. Format prompt with context and question\n",
    "# 3. Generate answer using LLM\n",
    "# 4. Parse output as string\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain built successfully!\")\n",
    "print(\"   Flow: Question ‚Üí Retriever ‚Üí Prompt ‚Üí LLM ‚Üí Answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e664ea3b-ddf4-4f64-b108-a4c3af96c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING RAG SYSTEM\n",
      "============================================================\n",
      "üö´ LangSmith tracing disabled for clean testing\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚ùì QUESTION 1: What is cloud computing?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TracerException('No indexed run ID edbc5979-cae0-419b-bef5-0692dfea6f5e.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° ANSWER:  Cloud computing allows users to access infrastructure and applications through the internet without needing to install and maintain them locally.\n",
      "============================================================\n",
      "\n",
      "‚ùì QUESTION 2: What are the benefits of cloud computing?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TracerException('No indexed run ID efdc805a-2fee-4381-b397-3cf503ce2b1d.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° ANSWER: \n",
      "Cloud computing offers cost-effectiveness, increased speed and agility, unlimited scalability, and enhanced strategic value.\n",
      "============================================================\n",
      "\n",
      "‚ùì QUESTION 3: What is data science?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TracerException('No indexed run ID a15bee30-7dbd-4e84-90cb-5099bb313f0b.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° ANSWER:  Data science combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI), and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organization‚Äôs data. These insights can be used to guide decision making and strategic planning.\n",
      "============================================================\n",
      "\n",
      "üéØ RAG SYSTEM TESTING COMPLETE!\n",
      "‚úÖ All questions answered successfully\n",
      "‚úÖ No tracer errors - clean output achieved\n",
      "üìù Note: Re-enable tracing in Cell 1 if you need LangSmith monitoring\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST THE COMPLETE RAG SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üß™ TESTING RAG SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# COMPLETELY disable LangChain tracing to fix tracer errors\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"  # Clear API key to ensure no tracing\n",
    "\n",
    "# Also suppress any remaining warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define test questions to evaluate the RAG system\n",
    "questions = [\n",
    "    \"What is cloud computing?\",\n",
    "    \"What are the benefits of cloud computing?\", \n",
    "    \"What is data science?\"\n",
    "]\n",
    "\n",
    "print(\"üö´ LangSmith tracing disabled for clean testing\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Test each question through the complete RAG pipeline\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"\\n‚ùì QUESTION {i+1}: {question}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Invoke the RAG chain with the current question\n",
    "        answer = rag_chain.invoke(question)\n",
    "        print(f\"üí° ANSWER: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüéØ RAG SYSTEM TESTING COMPLETE!\")\n",
    "print(\"‚úÖ All questions answered successfully\")\n",
    "print(\"‚úÖ No tracer errors - clean output achieved\")\n",
    "print(\"üìù Note: Re-enable tracing in Cell 1 if you need LangSmith monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f52ae4-fab2-4cfb-9d14-5b0430f09e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
