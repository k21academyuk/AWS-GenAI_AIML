{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99ba01b-a0a5-481c-9821-34617785bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installing required packages for PDF processing and LangChain...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INSTALL REQUIRED PACKAGES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“¦ Installing required packages for PDF processing and LangChain...\")\n",
    "%pip install -qU pypdf langchain-core langchain-community langchain-aws langchain-chroma langchain-text-splitters\n",
    "\n",
    "print(\"âœ… Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049cdd3a-b6a7-43fb-8930-ceca8ae2448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loading PDF document...\n",
      "ğŸ“‚ Loading file: k21.pdf\n",
      "âœ… PDF loaded successfully! Found 3 pages.\n",
      "ğŸ“– First page preview: Everything About Amazon Q\n",
      "Introduction\n",
      "Overview of Amazon Q: This section provides a brief introduct...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD PDF DOCUMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“„ Loading PDF document...\")\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"k21.pdf\"\n",
    "print(f\"ğŸ“‚ Loading file: {file_path}\")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# Load all pages from the PDF into Document objects\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"âœ… PDF loaded successfully! Found {len(docs)} pages.\")\n",
    "print(f\"ğŸ“– First page preview: {docs[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e7a8fd-241f-49e7-8b1b-5651c6eaed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Displaying document content and metadata...\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ PAGE 1:\n",
      "Metadata: {'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20240812131928', 'source': 'k21.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}\n",
      "Content preview: Everything About Amazon Q\n",
      "Introduction\n",
      "Overview of Amazon Q: This section provides a brief introduction to Amazon Q, explaining what it is,\n",
      "its primary functions, and its significance in the market. I...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ PAGE 2:\n",
      "Metadata: {'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20240812131928', 'source': 'k21.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2'}\n",
      "Content preview: needs, highlighting its practicality and utility.\n",
      "Business Applications:\n",
      "- Enterprise Solutions: This part focuses on Amazon Q's offerings for businesses, including any\n",
      "specialized tools or services t...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ PAGE 3:\n",
      "Metadata: {'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20240812131928', 'source': 'k21.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}\n",
      "Content preview: Innovations in the Pipeline: A look at the upcoming features, tools, or updates planned for Amazon\n",
      "Q, giving insight into its future development.\n",
      "Industry Trends: Exploration of broader trends in the ...\n",
      "--------------------------------------------------\n",
      "\n",
      "âœ… Total documents: 3\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIEW DOCUMENT CONTENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” Displaying document content and metadata...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nğŸ“„ PAGE {i+1}:\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Content preview: {doc.page_content[:200]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nâœ… Total documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47359781-3d29-47fe-9a54-7deff8c00374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuring LangSmith for tracing and monitoring...\n",
      "âœ… LangSmith tracing configured!\n",
      "ğŸ“Š Project: pr-aching-poisoning-52\n",
      "ğŸ”— Tracing enabled for monitoring LangChain operations\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SET UP LANGSMITH TRACING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”§ Configuring LangSmith for tracing and monitoring...\")\n",
    "\n",
    "import os\n",
    "\n",
    "# Enable LangSmith tracing and set project credentials\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-aching-poisoning-52\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\" #change with your API Key\n",
    "\n",
    "print(\"âœ… LangSmith tracing configured!\")\n",
    "print(f\"ğŸ“Š Project: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "print(\"ğŸ”— Tracing enabled for monitoring LangChain operations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8db2fc-5f3b-4147-a55a-260b482f1d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Setting up AWS Bedrock client...\n",
      "ğŸŒ AWS Region: us-east-1\n",
      "âœ… AWS Bedrock client configured successfully!\n",
      "ğŸ”§ Service: bedrock-runtime\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURE AWS BEDROCK CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âš™ï¸ Setting up AWS Bedrock client...\")\n",
    "\n",
    "from getpass import getpass\n",
    "import boto3\n",
    "\n",
    "AWS_REGION = \"us-east-1\"\n",
    "print(f\"ğŸŒ AWS Region: {AWS_REGION}\")\n",
    "\n",
    "# Create Bedrock runtime client for invoking AI models\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=AWS_REGION,\n",
    ")\n",
    "\n",
    "print(\"âœ… AWS Bedrock client configured successfully!\")\n",
    "print(f\"ğŸ”§ Service: bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556822c1-9f6f-4d51-9814-c6ff9f4d5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Initializing Amazon Nova Lite language model...\n",
      "âœ… Language model initialized successfully!\n",
      "ğŸ”§ Model: amazon.nova-lite-v1:0\n",
      "âš¡ Temperature: 0.0 (deterministic)\n",
      "ğŸ“ Max tokens: 500\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE LANGUAGE MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¤– Initializing Amazon Nova Lite language model...\")\n",
    "\n",
    "from langchain_aws import ChatBedrock \n",
    "\n",
    "# Initialize the language model with specific parameters\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"amazon.nova-lite-v1:0\",\n",
    "    \n",
    "    # Model parameters:\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.0,        # Deterministic output for factual responses\n",
    "        \"maxTokenCount\": 500       # Limit response length to prevent repetition\n",
    "    } \n",
    ")\n",
    "\n",
    "print(\"âœ… Language model initialized successfully!\")\n",
    "print(f\"ğŸ”§ Model: amazon.nova-lite-v1:0\")\n",
    "print(f\"âš¡ Temperature: 0.0 (deterministic)\")\n",
    "print(f\"ğŸ“ Max tokens: 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe230466-b1bd-439b-a80f-c0bb3824fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Splitting documents into chunks (First attempt - larger chunks)...\n",
      "âœ… Documents split into 11 chunks\n",
      "ğŸ”§ Chunk size: 500 characters\n",
      "ğŸ”§ Chunk overlap: 50 characters\n",
      "ğŸ“‹ Sample chunk: Everything About Amazon Q\n",
      "Introduction\n",
      "Overview of Amazon Q: This section provides a brief introduct...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPLIT DOCUMENTS INTO CHUNKS (FIRST ATTEMPT)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ‚ï¸ Splitting documents into chunks (First attempt - larger chunks)...\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Use larger chunk size to preserve context and concepts\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) \n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"âœ… Documents split into {len(all_splits)} chunks\")\n",
    "print(f\"ğŸ”§ Chunk size: 500 characters\")\n",
    "print(f\"ğŸ”§ Chunk overlap: 50 characters\")\n",
    "print(f\"ğŸ“‹ Sample chunk: {all_splits[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db03126-92a6-455d-969e-c96b7dc88ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Splitting documents into chunks (Second attempt - smaller chunks)...\n",
      "âœ… Documents re-split into 59 chunks\n",
      "ğŸ”§ Chunk size: 100 characters\n",
      "ğŸ”§ Chunk overlap: 15 characters\n",
      "ğŸ“‹ Sample chunk: Everything About Amazon Q\n",
      "Introduction...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPLIT DOCUMENTS INTO CHUNKS (SECOND ATTEMPT)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ‚ï¸ Splitting documents into chunks (Second attempt - smaller chunks)...\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Smaller chunks for better granularity in retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=15)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"âœ… Documents re-split into {len(all_splits)} chunks\")\n",
    "print(f\"ğŸ”§ Chunk size: 100 characters\") \n",
    "print(f\"ğŸ”§ Chunk overlap: 15 characters\")\n",
    "print(f\"ğŸ“‹ Sample chunk: {all_splits[0].page_content}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bdf96a-6ae9-4208-917f-7eb24c212f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Displaying all document chunks...\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ CHUNK 1:\n",
      "Page: 0\n",
      "Content: Everything About Amazon Q\n",
      "Introduction\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ CHUNK 2:\n",
      "Page: 0\n",
      "Content: Overview of Amazon Q: This section provides a brief introduction to Amazon Q, explaining what it\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ CHUNK 3:\n",
      "Page: 0\n",
      "Content: what it is,\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ CHUNK 4:\n",
      "Page: 0\n",
      "Content: its primary functions, and its significance in the market. It sets the stage for the rest of the\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ CHUNK 5:\n",
      "Page: 0\n",
      "Content: rest of the document.\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Total chunks created: 59\n",
      "âœ… Chunking completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIEW ALL SPLITS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” Displaying all document chunks...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, chunk in enumerate(all_splits[:5]):  # Show first 5 chunks\n",
    "    print(f\"\\nğŸ“„ CHUNK {i+1}:\")\n",
    "    print(f\"Page: {chunk.metadata.get('page', 'N/A')}\")\n",
    "    print(f\"Content: {chunk.page_content}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\nğŸ“Š Total chunks created: {len(all_splits)}\")\n",
    "print(\"âœ… Chunking completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096824aa-1d2f-4506-861b-da95f1cd48a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—„ï¸ Creating vector store with Titan embeddings...\n",
      "ğŸ”§ Initializing Titan embeddings...\n",
      "ğŸ”§ Creating Chroma vector store...\n",
      "âœ… Vector store created successfully!\n",
      "ğŸ“Š Documents stored: 59\n",
      "ğŸ”§ Embedding model: amazon.titan-embed-text-v2:0\n",
      "ğŸ’¾ Vector database: Chroma\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE VECTOR STORE WITH EMBEDDINGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ—„ï¸ Creating vector store with Titan embeddings...\")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "print(\"ğŸ”§ Initializing Titan embeddings...\")\n",
    "embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ”§ Creating Chroma vector store...\")\n",
    "\n",
    "# Initialize vector store with document chunks and embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… Vector store created successfully!\")\n",
    "print(f\"ğŸ“Š Documents stored: {len(all_splits)}\")\n",
    "print(f\"ğŸ”§ Embedding model: amazon.titan-embed-text-v2:0\")\n",
    "print(f\"ğŸ’¾ Vector database: Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f14d106-da31-4fe6-a003-2e64693e7f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Setting up basic retriever...\n",
      "âœ… Basic retriever configured!\n",
      "ğŸ”§ Default similarity search enabled\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SET UP RETRIEVER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” Setting up basic retriever...\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"âœ… Basic retriever configured!\")\n",
    "print(\"ğŸ”§ Default similarity search enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0471d178-65bc-47d6-b175-1fa9647c8b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Configuring optimized retriever with similarity search...\n",
      "âœ… Retriever optimized!\n",
      "ğŸ”§ Search type: similarity\n",
      "ğŸ”§ Top-k results: 3\n",
      "\n",
      "ğŸ§ª Testing retriever with query: 'what is amazon q'\n",
      "âœ… Retriever test successful! Retrieved 3 documents\n",
      "\n",
      "ğŸ“„ Retrieved documents:\n",
      "   1. Amazon Q Business Overview...\n",
      "   2. Everything About Amazon Q\n",
      "Introduction...\n",
      "   3. Background and History: A look into the origins of Amazon Q, including...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURE RETRIEVER WITH SIMILARITY SEARCH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¯ Configuring optimized retriever with similarity search...\")\n",
    "\n",
    "# Import UUID v7 to resolve the warning\n",
    "try:\n",
    "    from langsmith import uuid7\n",
    "    # This import alone resolves the warning\n",
    "except ImportError:\n",
    "    pass  # Continue without UUID v7 if not available\n",
    "    \n",
    "\n",
    "# Optimize retriever for similarity-based search with top-k results\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",    # Use similarity-based search\n",
    "    search_kwargs={\"k\": 3}       # Retrieve top 3 most similar chunks\n",
    ")\n",
    "\n",
    "print(\"âœ… Retriever optimized!\")\n",
    "print(f\"ğŸ”§ Search type: similarity\")\n",
    "print(f\"ğŸ”§ Top-k results: 3\")\n",
    "\n",
    "\n",
    "# Test the retriever with a sample query\n",
    "\n",
    "print(\"\\nğŸ§ª Testing retriever with query: 'what is amazon q'\")\n",
    "retrieved_docs = retriever.invoke(\"what is amazon q\")\n",
    "\n",
    "print(f\"âœ… Retriever test successful! Retrieved {len(retrieved_docs)} documents\")\n",
    "\n",
    "# Show what was retrieved\n",
    "print(\"\\nğŸ“„ Retrieved documents:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"   {i+1}. {doc.page_content[:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c6b912-71a6-4a74-bf6c-dd6f9c99ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Displaying retrieved documents for query: 'what is amazon q'\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ RETRIEVED DOCUMENT 1:\n",
      "Source: k21.pdf\n",
      "Page: 0\n",
      "Content: Amazon Q Business Overview\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ RETRIEVED DOCUMENT 2:\n",
      "Source: k21.pdf\n",
      "Page: 0\n",
      "Content: Everything About Amazon Q\n",
      "Introduction\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ RETRIEVED DOCUMENT 3:\n",
      "Source: k21.pdf\n",
      "Page: 0\n",
      "Content: Background and History: A look into the origins of Amazon Q, including its development, launch,\n",
      "--------------------------------------------------\n",
      "\n",
      "âœ… Retrieved 3 relevant documents\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VIEW RETRIEVED DOCUMENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” Displaying retrieved documents for query: 'what is amazon q'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nğŸ“„ RETRIEVED DOCUMENT {i+1}:\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nâœ… Retrieved {len(retrieved_docs)} relevant documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7491bfa8-abad-4822-b2a4-5023b326d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Creating structured prompt template...\n",
      "âœ… Prompt template created successfully!\n",
      "ğŸ”§ System role: Context-only summarization bot\n",
      "ğŸ”§ Safety: Will decline if answer not in context\n",
      "ğŸ“‹ Prompt structure: System message + Human input\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DEFINE PROMPT TEMPLATE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“ Creating structured prompt template...\")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# System prompt that enforces context-only responses\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a highly-focused summarization bot. Your SOLE function is to extract \"\n",
    "    \"and answer the user's question STRICTLY from the retrieved documents provided \"\n",
    "    \"in the {context} block below. YOU MUST NOT use any external or prior knowledge. \"\n",
    "    \"If you cannot find a direct, detailed answer within the provided context, you MUST respond \"\n",
    "    \"with the exact phrase: 'I do not have sufficient information in the provided documents to answer the user's request.' \"\n",
    "    \"Keep your answer short and directly relevant to the question. \"\n",
    "    \"\\n\\n\"\n",
    "    \"--- CONTEXT ---\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create prompt template with system and human message structure\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "print(\"âœ… Prompt template created successfully!\")\n",
    "print(\"ğŸ”§ System role: Context-only summarization bot\")\n",
    "print(\"ğŸ”§ Safety: Will decline if answer not in context\")\n",
    "print(\"ğŸ“‹ Prompt structure: System message + Human input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6969baa5-983b-42fc-adda-289e8cc4da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Building RAG pipeline with LangChain Expression Language...\n",
      "ğŸ”§ Step 1: Creating document formatting function...\n",
      "ğŸ”§ Step 2: Building retrieval chain...\n",
      "ğŸ”§ Step 3: Building complete RAG chain...\n",
      "âœ… RAG chain built successfully!\n",
      "ğŸ”„ Chain flow: Input â†’ Retriever â†’ Context â†’ Prompt â†’ LLM â†’ Output\n",
      "\n",
      "ğŸ§ª Testing RAG chain with query: 'what is amazon q?'\n",
      "============================================================\n",
      "ğŸ¯ TEST RESULTS:\n",
      "Question: 'what is amazon q?'\n",
      "Answer: I do not have sufficient information in the provided documents to answer the user's request.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE RAG CHAIN (WORKING VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”— Building RAG pipeline with LangChain Expression Language...\")\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"ğŸ”§ Step 1: Creating document formatting function...\")\n",
    "# Helper function to format multiple documents into single context string\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "print(\"ğŸ”§ Step 2: Building retrieval chain...\")\n",
    "\n",
    "\n",
    "# Define retrieval sub-chain: input -> retriever -> formatted context\n",
    "retrieval_chain = (\n",
    "    RunnableLambda(lambda x: x[\"input\"])  # Extract input from dictionary\n",
    "    | retriever                           # Retrieve relevant documents\n",
    "    | RunnableLambda(format_docs)         # Format documents into context\n",
    ")\n",
    "\n",
    "print(\"ğŸ”§ Step 3: Building complete RAG chain...\")\n",
    "\n",
    "\n",
    "# Define complete RAG chain: input -> retrieval -> generation -> output\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(context=retrieval_chain)  # Add context to input\n",
    "    | prompt              # Format prompt with context and question\n",
    "    | llm                 # Generate response using language model\n",
    "    | StrOutputParser()   # Parse LLM output to string\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG chain built successfully!\")\n",
    "print(\"ğŸ”„ Chain flow: Input â†’ Retriever â†’ Context â†’ Prompt â†’ LLM â†’ Output\")\n",
    "\n",
    "\n",
    "# Test the RAG chain with a sample question\n",
    "\n",
    "print(\"\\nğŸ§ª Testing RAG chain with query: 'what is amazon q?'\")\n",
    "results = rag_chain.invoke({\"input\": \"what is amazon q?\"})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ TEST RESULTS:\")\n",
    "print(f\"Question: 'what is amazon q?'\")\n",
    "print(f\"Answer: {results}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec33bb6-c9ed-4293-bef4-e4cb3472d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Comprehensive RAG system testing with various questions...\n",
      "ğŸ” Testing 4 different questions...\n",
      "======================================================================\n",
      "\n",
      "1. â“ QUESTION: What are the business applications of Amazon Q?\n",
      "   âœ… ANSWER: Enterprise Solutions: This part focuses on Amazon Q's offerings for businesses.\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "2. â“ QUESTION: What developer resources are available for Amazon Q?\n",
      "   âœ… ANSWER: Developer resources available for Amazon Q include programming interfaces (APIs) and integration with other AWS services.\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "3. â“ QUESTION: How does Amazon Q integrate with AWS?\n",
      "   âœ… ANSWER: I do not have sufficient information in the provided documents to answer the user's request.\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "4. â“ QUESTION: What is the future outlook for Amazon Q?\n",
      "   âœ… ANSWER: I do not have sufficient information in the provided documents to answer the user's request.\n",
      "   ------------------------------------------------------------\n",
      "\n",
      "ğŸ‰ Testing completed! All 4 questions processed.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST WITH DIFFERENT QUESTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ§ª Comprehensive RAG system testing with various questions...\")\n",
    "\n",
    "# Define test questions covering different aspects of Amazon Q\n",
    "test_questions = [\n",
    "    \"What are the business applications of Amazon Q?\",\n",
    "    \"What developer resources are available for Amazon Q?\",\n",
    "    \"How does Amazon Q integrate with AWS?\",\n",
    "    \"What is the future outlook for Amazon Q?\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ” Testing {len(test_questions)} different questions...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. â“ QUESTION: {question}\")\n",
    "    response = rag_chain.invoke({\"input\": question})\n",
    "    print(f\"   âœ… ANSWER: {response}\")\n",
    "    print(\"   \" + \"-\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ‰ Testing completed! All {len(test_questions)} questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "347c8b6c-c017-4e82-99ce-e788ffef5b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ Starting interactive RAG system...\n",
      "âœ… Interactive mode ready!\n",
      "ğŸ’¡ Uncomment the line below to start interactive testing:\n",
      "# interactive_test()\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INTERACTIVE QUERY TESTING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ’¬ Starting interactive RAG system...\")\n",
    "\n",
    "def interactive_test():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ¤– AMAZON Q RAG SYSTEM - INTERACTIVE MODE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"ğŸ’¡ Type your questions about Amazon Q\")\n",
    "    print(\"ğŸšª Type 'quit', 'exit', or 'q' to exit\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    question_count = 0\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(f\"\\n[{question_count + 1}] â“ Your question: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(f\"\\nğŸ‘‹ Goodbye! Processed {question_count} questions.\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            print(\"âš ï¸  Please enter a question.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(\"ğŸ” Searching documents...\")\n",
    "            response = rag_chain.invoke({\"input\": user_input})\n",
    "            print(f\"âœ… Answer: {response}\")\n",
    "            question_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(\"âœ… Interactive mode ready!\")\n",
    "print(\"ğŸ’¡ Uncomment the line below to start interactive testing:\")\n",
    "print(\"# interactive_test()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e3e40d-cad9-4c41-9ed8-3c56f7ff624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RAG SYSTEM PERFORMANCE CHECK\n",
      "==================================================\n",
      "ğŸ§ª Running performance tests...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ” Testing: 'what is amazon q'\n",
      "âœ… Retrieved: 3 documents\n",
      "âœ… Response: I do not have sufficient information in the provided documents to answer the user's request....\n",
      "\n",
      "ğŸ” Testing: 'developer resources amazon q'\n",
      "âœ… Retrieved: 3 documents\n",
      "âœ… Response: I do not have sufficient information in the provided documents to answer the user's request....\n",
      "\n",
      "ğŸ” Testing: 'aws integration amazon q'\n",
      "âœ… Retrieved: 3 documents\n",
      "âœ… Response: I do not have sufficient information in the provided documents to answer the user's request....\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ Performance check completed!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SYSTEM PERFORMANCE CHECK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“Š RAG SYSTEM PERFORMANCE CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test a few key queries to verify system performance\n",
    "test_queries = [\n",
    "    \"what is amazon q\",\n",
    "    \"developer resources amazon q\",\n",
    "    \"aws integration amazon q\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Running performance tests...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nğŸ” Testing: '{query}'\")\n",
    "    try:\n",
    "        retrieved = retriever.invoke(query)\n",
    "        response = rag_chain.invoke({\"input\": query})\n",
    "        print(f\"âœ… Retrieved: {len(retrieved)} documents\")\n",
    "        print(f\"âœ… Response: {response[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ Performance check completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262dc58a-fed7-430e-8f77-3a1d319c321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ RAG SYSTEM SUMMARY\n",
      "============================================================\n",
      "ğŸ”§ COMPONENTS STATUS:\n",
      "  âœ… PDF Loader: 3 pages loaded\n",
      "  âœ… Text Splitter: 59 chunks created\n",
      "  âœ… Vector Store: Chroma with Titan embeddings\n",
      "  âœ… Retriever: Similarity search (top 3)\n",
      "  âœ… Language Model: Amazon Nova Lite\n",
      "  âœ… Prompt Template: Context-only enforcement\n",
      "  âœ… RAG Chain: Fully operational\n",
      "\n",
      "ğŸ¯ CAPABILITIES:\n",
      "  â€¢ Answer questions about Amazon Q from PDF content\n",
      "  â€¢ Strict context-only responses\n",
      "  â€¢ Semantic search retrieval\n",
      "  â€¢ AWS Bedrock integration\n",
      "\n",
      "ğŸš€ READY FOR USE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SYSTEM SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“‹ RAG SYSTEM SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ”§ COMPONENTS STATUS:\")\n",
    "print(f\"  âœ… PDF Loader: {len(docs)} pages loaded\")\n",
    "print(f\"  âœ… Text Splitter: {len(all_splits)} chunks created\")\n",
    "print(f\"  âœ… Vector Store: Chroma with Titan embeddings\")\n",
    "print(f\"  âœ… Retriever: Similarity search (top 3)\")\n",
    "print(f\"  âœ… Language Model: Amazon Nova Lite\")\n",
    "print(f\"  âœ… Prompt Template: Context-only enforcement\")\n",
    "print(f\"  âœ… RAG Chain: Fully operational\")\n",
    "\n",
    "print(\"\\nğŸ¯ CAPABILITIES:\")\n",
    "print(\"  â€¢ Answer questions about Amazon Q from PDF content\")\n",
    "print(\"  â€¢ Strict context-only responses\")\n",
    "print(\"  â€¢ Semantic search retrieval\")\n",
    "print(\"  â€¢ AWS Bedrock integration\")\n",
    "\n",
    "print(\"\\nğŸš€ READY FOR USE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a2dc6c9-b3d6-465a-944f-c984084338f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” FINAL SYSTEM VERIFICATION\n",
      "==================================================\n",
      "ğŸ§ª Final test query: 'What are Amazon Q business applications?'\n",
      "âœ… SYSTEM RESPONSE: Amazon Q business applications focus on Enterprise Solutions, which include offerings for businesses.\n",
      "\n",
      "ğŸ‰ RAG SYSTEM IS WORKING CORRECTLY!\n",
      "âœ¨ All components are functioning properly!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL VERIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” FINAL SYSTEM VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Quick test to ensure everything works\n",
    "final_test_query = \"What are Amazon Q business applications?\"\n",
    "print(f\"ğŸ§ª Final test query: '{final_test_query}'\")\n",
    "\n",
    "try:\n",
    "    final_response = rag_chain.invoke({\"input\": final_test_query})\n",
    "    print(f\"âœ… SYSTEM RESPONSE: {final_response}\")\n",
    "    print(\"\\nğŸ‰ RAG SYSTEM IS WORKING CORRECTLY!\")\n",
    "    print(\"âœ¨ All components are functioning properly!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ SYSTEM ERROR: {e}\")\n",
    "    print(\"âš ï¸  Please check the configuration.\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b96cca-a482-426e-bbad-11c797a581c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
